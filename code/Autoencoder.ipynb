{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "607752111aa94751aa5e39f348869add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b4f108fb0db940d6a917c1548aa4f51c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4519b0808524b2bb749d000ed5f614f",
              "IPY_MODEL_7f34d35952b64b32b2417c359bebe649"
            ]
          }
        },
        "b4f108fb0db940d6a917c1548aa4f51c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4519b0808524b2bb749d000ed5f614f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_307fdd9e22d5471cb6c9365c0247d414",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35069eb4246c45d985b58bf0da92af52"
          }
        },
        "7f34d35952b64b32b2417c359bebe649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08b1f1eb8d414e42960207606d7442ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:00&lt;00:00, 13060852.66it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8176a273667e4deb8369218f7ad044d8"
          }
        },
        "307fdd9e22d5471cb6c9365c0247d414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35069eb4246c45d985b58bf0da92af52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08b1f1eb8d414e42960207606d7442ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8176a273667e4deb8369218f7ad044d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1f93cd41359467bb1c2fbdd14c6d403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_883bda33b172464e8203a57b5143360a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_80aa6bea96aa49a9b8c9ea12c9246a4c",
              "IPY_MODEL_798b6124b9ae4e64948fb929960c7af6"
            ]
          }
        },
        "883bda33b172464e8203a57b5143360a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80aa6bea96aa49a9b8c9ea12c9246a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_819a9ca43c0142e28b81edccfbfe629e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e255cb5570a495fa130253eb0f3c707"
          }
        },
        "798b6124b9ae4e64948fb929960c7af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d8b3ecb9b3394aadb285d4106fdbed5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:30&lt;00:00, 1065.86it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91dc350871ac4af2844738771336ecee"
          }
        },
        "819a9ca43c0142e28b81edccfbfe629e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e255cb5570a495fa130253eb0f3c707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8b3ecb9b3394aadb285d4106fdbed5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91dc350871ac4af2844738771336ecee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48e1b003cd074b72bdbc98048f827dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d6f50c507db4070900127759c4821eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad4232de10d5433396196ab218ed7697",
              "IPY_MODEL_28a5978f2891481ab957dba9ec277137"
            ]
          }
        },
        "2d6f50c507db4070900127759c4821eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad4232de10d5433396196ab218ed7697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_61e69e0374b345a9bc635ca7a9efa84c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b667eaefc69d4a28a063cb94b1faf2f3"
          }
        },
        "28a5978f2891481ab957dba9ec277137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e90a474cc7d84e7b96211006e5ef9459",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:00&lt;00:00, 3584140.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b87b7ccf3fd143c7841c43eab5f6e265"
          }
        },
        "61e69e0374b345a9bc635ca7a9efa84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b667eaefc69d4a28a063cb94b1faf2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e90a474cc7d84e7b96211006e5ef9459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b87b7ccf3fd143c7841c43eab5f6e265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f27d511347c4a09b51acb3deeff7967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ffeec0c4213149a99086d5d1f882f2d7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_949f07d35ab941b0b0342a15d0f296a4",
              "IPY_MODEL_855b666043b34ba4bd8ccc3db16908c0"
            ]
          }
        },
        "ffeec0c4213149a99086d5d1f882f2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "949f07d35ab941b0b0342a15d0f296a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_644ce9cc2a2a4b8f8d1e40298ef1e591",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44d4d1e0fddf47cdbfb8b55395fef9d5"
          }
        },
        "855b666043b34ba4bd8ccc3db16908c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d0d5657f42994a2da3dfbead16c64249",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:00&lt;00:00, 35222.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_537edd5fc08f4f5094fed3b56ef6b556"
          }
        },
        "644ce9cc2a2a4b8f8d1e40298ef1e591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44d4d1e0fddf47cdbfb8b55395fef9d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0d5657f42994a2da3dfbead16c64249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "537edd5fc08f4f5094fed3b56ef6b556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfVRERpBxa5S"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J_DA159xbvE",
        "outputId": "bf5ba6e8-977c-406a-b211-506b6ad99819"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYrbCZt9PXg8"
      },
      "source": [
        "!cp '/content/gdrive/My Drive/Diss/Yu/train_data.zip' '/content/train_data.zip'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYG78azbP_u7",
        "outputId": "dcf5fe5f-d44f-4d63-ae76-2e16af5fa3d6"
      },
      "source": [
        "!unzip 'train_data.zip'"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train_data.zip\n",
            "replace train_data/gan_3_img_6719.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxbrPeodxdwU"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/')\n",
        "import model_architectures as ma"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-GGB73QhQBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437,
          "referenced_widgets": [
            "607752111aa94751aa5e39f348869add",
            "b4f108fb0db940d6a917c1548aa4f51c",
            "d4519b0808524b2bb749d000ed5f614f",
            "7f34d35952b64b32b2417c359bebe649",
            "307fdd9e22d5471cb6c9365c0247d414",
            "35069eb4246c45d985b58bf0da92af52",
            "08b1f1eb8d414e42960207606d7442ef",
            "8176a273667e4deb8369218f7ad044d8",
            "f1f93cd41359467bb1c2fbdd14c6d403",
            "883bda33b172464e8203a57b5143360a",
            "80aa6bea96aa49a9b8c9ea12c9246a4c",
            "798b6124b9ae4e64948fb929960c7af6",
            "819a9ca43c0142e28b81edccfbfe629e",
            "2e255cb5570a495fa130253eb0f3c707",
            "d8b3ecb9b3394aadb285d4106fdbed5a",
            "91dc350871ac4af2844738771336ecee",
            "48e1b003cd074b72bdbc98048f827dcf",
            "2d6f50c507db4070900127759c4821eb",
            "ad4232de10d5433396196ab218ed7697",
            "28a5978f2891481ab957dba9ec277137",
            "61e69e0374b345a9bc635ca7a9efa84c",
            "b667eaefc69d4a28a063cb94b1faf2f3",
            "e90a474cc7d84e7b96211006e5ef9459",
            "b87b7ccf3fd143c7841c43eab5f6e265",
            "7f27d511347c4a09b51acb3deeff7967",
            "ffeec0c4213149a99086d5d1f882f2d7",
            "949f07d35ab941b0b0342a15d0f296a4",
            "855b666043b34ba4bd8ccc3db16908c0",
            "644ce9cc2a2a4b8f8d1e40298ef1e591",
            "44d4d1e0fddf47cdbfb8b55395fef9d5",
            "d0d5657f42994a2da3dfbead16c64249",
            "537edd5fc08f4f5094fed3b56ef6b556"
          ]
        },
        "outputId": "35d72042-34a2-420e-e425-167bc98f4d09"
      },
      "source": [
        "netG1 = ma.Generator1(0)\n",
        "model_dict1 = torch.load('/content/gdrive/My Drive/Diss/trained_models/GAN_1', map_location=torch.device('cpu'))\n",
        "netG1.load_state_dict(model_dict1['G_state_dict'])\n",
        "\n",
        "netG2 = ma.Generator2(0)\n",
        "model_dict2 = torch.load('/content/gdrive/My Drive/Diss/trained_models/GAN_2', map_location=torch.device('cpu'))\n",
        "netG2.load_state_dict(model_dict2['G_state_dict'])\n",
        "\n",
        "netG3 = ma.Generator3(0)\n",
        "model_dict3 = torch.load('/content/gdrive/My Drive/Diss/trained_models/GAN_3', map_location=torch.device('cpu'))\n",
        "netG3.load_state_dict(model_dict3['G_state_dict'])\n",
        "\n",
        "real_train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=True, download=True, transform=torchvision.transforms.ToTensor()), batch_size=15000)\n",
        "real_images, _ = next(iter(real_train_loader))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /files/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "607752111aa94751aa5e39f348869add",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /files/MNIST/raw/train-images-idx3-ubyte.gz to /files/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /files/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1f93cd41359467bb1c2fbdd14c6d403",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /files/MNIST/raw/train-labels-idx1-ubyte.gz to /files/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /files/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48e1b003cd074b72bdbc98048f827dcf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /files/MNIST/raw/t10k-images-idx3-ubyte.gz to /files/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f27d511347c4a09b51acb3deeff7967",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /files/MNIST/raw/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ6-CAu2JW2W",
        "outputId": "03befb16-8579-4bf3-cc95-78924f84d720"
      },
      "source": [
        "netG1 = ma.Generator1(0)\n",
        "model_dict1 = torch.load('/content/gdrive/My Drive/Diss/trained_models/GAN_1', map_location=torch.device('cpu'))\n",
        "netG1.load_state_dict(model_dict1['G_state_dict'])\n",
        "noise = torch.randn(2,100,1,1)\n",
        "netG1(noise).view(-1).shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1568])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WBMUTP87ivA"
      },
      "source": [
        "\n",
        "for i in range(15000):\n",
        "  if i%100 == 0:\n",
        "    print(i)\n",
        "  noise = torch.randn(100,1,1)\n",
        "  np.save('/content/gdrive/My Drive/Diss/Yu/train_data/real_img_{}.npy'.format(i+1), real_images[i].numpy())\n",
        "  img_to_labels_dict['real_img_{}'.format(i+1)] = 0\n",
        "  np.save('/content/gdrive/My Drive/Diss/Yu/train_data/gan_1_img_{}.npy'.format(i+1), netG1(noise).detach().numpy())\n",
        "  img_to_labels_dict['gan_1_img_{}'.format(i+1)] = 1\n",
        "  np.save('/content/gdrive/My Drive/Diss/Yu/train_data/gan_2_img_{}.npy'.format(i+1), netG2(noise).detach().numpy())\n",
        "  img_to_labels_dict['gan_2_img_{}'.format(i+1)] = 1\n",
        "  np.save('/content/gdrive/My Drive/Diss/Yu/train_data/gan_3_img_{}.npy'.format(i+1), netG3(noise).detach().numpy())\n",
        "  img_to_labels_dict['gan_3_img_{}'.format(i+1)] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vQf3l45GVzN"
      },
      "source": [
        "partition = {}\n",
        "partition['training data'] = ['{}_img_{}'.format(source, num) for source in ['gan_1','gan_2','gan_3','real'] for num in range(1,10001)]\n",
        "partition['validation data'] = ['{}_img_{}'.format(source, num) for source in ['gan_1','gan_2','gan_3','real'] for num in range(10001,15001)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqUk52LDHPmR"
      },
      "source": [
        "img_to_labels_dict = {}\n",
        "label_mapping = {'real':0, 'gan_1':1, 'gan_2':2, 'gan_3':3}\n",
        "for num in range(1,150001):\n",
        "  for source in label_mapping.keys():\n",
        "    img_to_labels_dict['{}_img_{}'.format(source,num)] = label_mapping[source]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch9QGE1mAtBS"
      },
      "source": [
        "class AutoEncoderDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, list_IDs, labels):\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.list_IDs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        ID = self.list_IDs[index]\n",
        "        img = torch.from_numpy(np.load('/content/train_data/' + ID + '.npy'))\n",
        "      \n",
        "        label = self.labels[ID]\n",
        "\n",
        "        return img, label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8oOK8Joizec",
        "outputId": "845f570d-a4eb-4957-8cfe-1eb1e824de3d"
      },
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "autoEnc = ma.Autoencoder()\n",
        "autoEnc.to(device)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Autoencoder(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (maxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (convTr1): ConvTranspose2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (convTr2): ConvTranspose2d(16, 1, kernel_size=(2, 2), stride=(2, 2))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58_wB0JW-3_q"
      },
      "source": [
        "manualSeed = 600\n",
        "\n",
        "torch.manual_seed(manualSeed)\n",
        "random.seed(manualSeed)\n",
        "np.random.seed(manualSeed)\n",
        "\n",
        "real_fp = torch.randn(784, requires_grad=True, device=device)\n",
        "gan1_fp = torch.randn(784, requires_grad=True, device=device)\n",
        "gan2_fp = torch.randn(784, requires_grad=True, device=device)\n",
        "gan3_fp = torch.randn(784, requires_grad=True, device = device)\n",
        "fps = [real_fp, gan1_fp, gan2_fp, gan3_fp]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxXb8lEjiiR8"
      },
      "source": [
        "from itertools import chain\n",
        "optimizer = optim.Adam(chain(autoEnc.parameters(), iter(fps)))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iLTaaix7JJg"
      },
      "source": [
        "def custom_loss(output, target, source):\n",
        "\n",
        "  output_vec = torch.reshape(output, (-1, 784)) #flatten batch of matrices to batch of vectors\n",
        "  target_vec = torch.reshape(target, (-1, 784)) #flatten batch of matrices to batch of vectors\n",
        "  img_fps_vec = target_vec - output_vec     #get fingerprint\n",
        "  img_fps_vec_norm = F.normalize(img_fps_vec - torch.mean(img_fps_vec, dim=1).unsqueeze(1), dim=1) #normalize fingerprint for each image in batch\n",
        "  fps_vec_norm = [F.normalize(fp - torch.mean(fp), dim=0) for fp in fps] #normalize each model fingerprint\n",
        "  cov_vecs = [(torch.mv(img_fps_vec_norm, fp_vec_norm)) for fp_vec_norm in fps_vec_norm] #get covariance of each image with each fingerprint\n",
        "  ce_loss_criterion = nn.CrossEntropyLoss()\n",
        "  ce_loss = ce_loss_criterion(torch.stack(cov_vecs, dim=1), source) \n",
        "  return ce_loss\n",
        "  "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB7gjve0WqAk"
      },
      "source": [
        "params = {'batch_size': 256,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 6}\n",
        "\n",
        "\n",
        "training_set = AutoEncoderDataset(partition['training data'], img_to_labels_dict)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = AutoEncoderDataset(partition['validation data'], img_to_labels_dict)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzzyCcQ1griO"
      },
      "source": [
        "mse_train_losses = []\n",
        "fp_train_losses = []\n",
        "mse_val_losses = []\n",
        "fp_val_losses = []\n",
        "\n",
        "mseCriterion = nn.MSELoss()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LaWA_cfGPfd"
      },
      "source": [
        "def train_autoenc(start_epoch, end_epoch):\n",
        "  for epoch in range(start_epoch, end_epoch):\n",
        "    print(\"Starting epoch {}\".format(epoch))\n",
        "      # Training\n",
        "    for i, (local_batch, local_labels) in enumerate(training_generator):\n",
        "\n",
        "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = autoEnc(local_batch)\n",
        "        \n",
        "        mse_loss = mseCriterion(output, local_batch)\n",
        "        fp_loss = custom_loss(output, local_batch, local_labels)\n",
        "\n",
        "        cum_loss = 5*mse_loss + 2*fp_loss\n",
        "        cum_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "          print('[%d/%d][%d/%d]\\tTrain Reconstruction Loss %.4f\\t Train Correlation Loss %.4f'\n",
        "          % (epoch, end_epoch, i, len(training_generator), mse_loss.item(), fp_loss.item()))\n",
        "      \n",
        "    mse_train_losses.append(mse_loss.item())\n",
        "    fp_train_losses.append(fp_loss.item())\n",
        "\n",
        "    # Validation\n",
        "    mse_loss_sum = 0\n",
        "    fp_loss_sum = 0\n",
        "    with torch.set_grad_enabled(False):\n",
        "        for local_batch, local_labels in validation_generator:\n",
        "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
        "            output = autoEnc(local_batch)\n",
        "\n",
        "            mse_loss = mseCriterion(output, local_batch)\n",
        "            fp_loss = custom_loss(output, local_batch, local_labels)\n",
        "\n",
        "            mse_loss_sum += mse_loss.item()\n",
        "            fp_loss_sum += fp_loss.item()\n",
        "\n",
        "    avg_mse_loss = mse_loss_sum/len(validation_generator)\n",
        "    avg_fp_loss = fp_loss_sum/len(validation_generator)\n",
        "    print(\"Val Reconstruction Loss %.4f\\t Val Correlation Loss %.4f\"%(avg_mse_loss, avg_fp_loss))\n",
        "    mse_val_losses.append(avg_mse_loss)\n",
        "    fp_val_losses.append(avg_fp_loss)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt9XWERuGhP6"
      },
      "source": [
        "def create_checkpoint():\n",
        "  torch.save({\n",
        "            'model_state_dict': autoEnc.state_dict(),\n",
        "            'optim_state_dict': optimizer.state_dict(),\n",
        "            'mse_train_losses': mse_train_losses,\n",
        "            'fp_train_losses': fp_train_losses,\n",
        "            'mse_val_losses': mse_val_losses,\n",
        "            'fp_val_losses': fp_val_losses\n",
        "            }, 'gdrive/My Drive/Diss/trained_models/Autoencoder')\n",
        "  np.save('gdrive/My Drive/Diss/Yu/Fingerprints/print_real', real_fp.to('cpu').detach().numpy())\n",
        "  np.save('gdrive/My Drive/Diss/Yu/Fingerprints/print_GAN_1', gan1_fp.to('cpu').detach().numpy())\n",
        "  np.save('gdrive/My Drive/Diss/Yu/Fingerprints/print_GAN_2', gan2_fp.to('cpu').detach().numpy())\n",
        "  np.save('gdrive/My Drive/Diss/Yu/Fingerprints/print_GAN_3', gan3_fp.to('cpu').detach().numpy())"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FGMr7gaO_Mw",
        "outputId": "85e426ae-1fc7-43f8-c0c8-7dca99a95e51"
      },
      "source": [
        "train_autoenc(0, 100)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0/100][0/157]\tTrain Reconstruction Loss 0.1610\t Train Correlation Loss 1.3865\n",
            "[0/100][50/157]\tTrain Reconstruction Loss 0.1419\t Train Correlation Loss 1.3865\n",
            "[0/100][100/157]\tTrain Reconstruction Loss 0.0975\t Train Correlation Loss 1.3851\n",
            "[0/100][150/157]\tTrain Reconstruction Loss 0.0482\t Train Correlation Loss 1.3859\n",
            "Val Reconstruction Loss 0.0445\t Val Correlation Loss 1.3851\n",
            "Starting epoch 1\n",
            "[1/100][0/157]\tTrain Reconstruction Loss 0.0433\t Train Correlation Loss 1.3837\n",
            "[1/100][50/157]\tTrain Reconstruction Loss 0.0281\t Train Correlation Loss 1.3828\n",
            "[1/100][100/157]\tTrain Reconstruction Loss 0.0237\t Train Correlation Loss 1.3814\n",
            "[1/100][150/157]\tTrain Reconstruction Loss 0.0220\t Train Correlation Loss 1.3818\n",
            "Val Reconstruction Loss 0.0218\t Val Correlation Loss 1.3811\n",
            "Starting epoch 2\n",
            "[2/100][0/157]\tTrain Reconstruction Loss 0.0222\t Train Correlation Loss 1.3785\n",
            "[2/100][50/157]\tTrain Reconstruction Loss 0.0203\t Train Correlation Loss 1.3788\n",
            "[2/100][100/157]\tTrain Reconstruction Loss 0.0206\t Train Correlation Loss 1.3801\n",
            "[2/100][150/157]\tTrain Reconstruction Loss 0.0194\t Train Correlation Loss 1.3801\n",
            "Val Reconstruction Loss 0.0199\t Val Correlation Loss 1.3773\n",
            "Starting epoch 3\n",
            "[3/100][0/157]\tTrain Reconstruction Loss 0.0196\t Train Correlation Loss 1.3750\n",
            "[3/100][50/157]\tTrain Reconstruction Loss 0.0192\t Train Correlation Loss 1.3776\n",
            "[3/100][100/157]\tTrain Reconstruction Loss 0.0197\t Train Correlation Loss 1.3760\n",
            "[3/100][150/157]\tTrain Reconstruction Loss 0.0192\t Train Correlation Loss 1.3714\n",
            "Val Reconstruction Loss 0.0190\t Val Correlation Loss 1.3729\n",
            "Starting epoch 4\n",
            "[4/100][0/157]\tTrain Reconstruction Loss 0.0196\t Train Correlation Loss 1.3706\n",
            "[4/100][50/157]\tTrain Reconstruction Loss 0.0187\t Train Correlation Loss 1.3730\n",
            "[4/100][100/157]\tTrain Reconstruction Loss 0.0187\t Train Correlation Loss 1.3698\n",
            "[4/100][150/157]\tTrain Reconstruction Loss 0.0186\t Train Correlation Loss 1.3660\n",
            "Val Reconstruction Loss 0.0186\t Val Correlation Loss 1.3678\n",
            "Starting epoch 5\n",
            "[5/100][0/157]\tTrain Reconstruction Loss 0.0183\t Train Correlation Loss 1.3664\n",
            "[5/100][50/157]\tTrain Reconstruction Loss 0.0189\t Train Correlation Loss 1.3648\n",
            "[5/100][100/157]\tTrain Reconstruction Loss 0.0179\t Train Correlation Loss 1.3653\n",
            "[5/100][150/157]\tTrain Reconstruction Loss 0.0187\t Train Correlation Loss 1.3624\n",
            "Val Reconstruction Loss 0.0184\t Val Correlation Loss 1.3619\n",
            "Starting epoch 6\n",
            "[6/100][0/157]\tTrain Reconstruction Loss 0.0191\t Train Correlation Loss 1.3554\n",
            "[6/100][50/157]\tTrain Reconstruction Loss 0.0185\t Train Correlation Loss 1.3579\n",
            "[6/100][100/157]\tTrain Reconstruction Loss 0.0182\t Train Correlation Loss 1.3617\n",
            "[6/100][150/157]\tTrain Reconstruction Loss 0.0184\t Train Correlation Loss 1.3551\n",
            "Val Reconstruction Loss 0.0185\t Val Correlation Loss 1.3553\n",
            "Starting epoch 7\n",
            "[7/100][0/157]\tTrain Reconstruction Loss 0.0179\t Train Correlation Loss 1.3508\n",
            "[7/100][50/157]\tTrain Reconstruction Loss 0.0192\t Train Correlation Loss 1.3556\n",
            "[7/100][100/157]\tTrain Reconstruction Loss 0.0189\t Train Correlation Loss 1.3489\n",
            "[7/100][150/157]\tTrain Reconstruction Loss 0.0186\t Train Correlation Loss 1.3504\n",
            "Val Reconstruction Loss 0.0187\t Val Correlation Loss 1.3480\n",
            "Starting epoch 8\n",
            "[8/100][0/157]\tTrain Reconstruction Loss 0.0187\t Train Correlation Loss 1.3531\n",
            "[8/100][50/157]\tTrain Reconstruction Loss 0.0181\t Train Correlation Loss 1.3528\n",
            "[8/100][100/157]\tTrain Reconstruction Loss 0.0180\t Train Correlation Loss 1.3342\n",
            "[8/100][150/157]\tTrain Reconstruction Loss 0.0188\t Train Correlation Loss 1.3413\n",
            "Val Reconstruction Loss 0.0190\t Val Correlation Loss 1.3405\n",
            "Starting epoch 9\n",
            "[9/100][0/157]\tTrain Reconstruction Loss 0.0199\t Train Correlation Loss 1.3432\n",
            "[9/100][50/157]\tTrain Reconstruction Loss 0.0190\t Train Correlation Loss 1.3388\n",
            "[9/100][100/157]\tTrain Reconstruction Loss 0.0197\t Train Correlation Loss 1.3390\n",
            "[9/100][150/157]\tTrain Reconstruction Loss 0.0191\t Train Correlation Loss 1.3307\n",
            "Val Reconstruction Loss 0.0194\t Val Correlation Loss 1.3325\n",
            "Starting epoch 10\n",
            "[10/100][0/157]\tTrain Reconstruction Loss 0.0199\t Train Correlation Loss 1.3327\n",
            "[10/100][50/157]\tTrain Reconstruction Loss 0.0195\t Train Correlation Loss 1.3291\n",
            "[10/100][100/157]\tTrain Reconstruction Loss 0.0193\t Train Correlation Loss 1.3324\n",
            "[10/100][150/157]\tTrain Reconstruction Loss 0.0193\t Train Correlation Loss 1.3161\n",
            "Val Reconstruction Loss 0.0196\t Val Correlation Loss 1.3240\n",
            "Starting epoch 11\n",
            "[11/100][0/157]\tTrain Reconstruction Loss 0.0206\t Train Correlation Loss 1.3216\n",
            "[11/100][50/157]\tTrain Reconstruction Loss 0.0200\t Train Correlation Loss 1.3255\n",
            "[11/100][100/157]\tTrain Reconstruction Loss 0.0193\t Train Correlation Loss 1.3192\n",
            "[11/100][150/157]\tTrain Reconstruction Loss 0.0202\t Train Correlation Loss 1.3130\n",
            "Val Reconstruction Loss 0.0201\t Val Correlation Loss 1.3172\n",
            "Starting epoch 12\n",
            "[12/100][0/157]\tTrain Reconstruction Loss 0.0203\t Train Correlation Loss 1.3166\n",
            "[12/100][50/157]\tTrain Reconstruction Loss 0.0199\t Train Correlation Loss 1.3112\n",
            "[12/100][100/157]\tTrain Reconstruction Loss 0.0201\t Train Correlation Loss 1.3124\n",
            "[12/100][150/157]\tTrain Reconstruction Loss 0.0207\t Train Correlation Loss 1.3008\n",
            "Val Reconstruction Loss 0.0204\t Val Correlation Loss 1.3085\n",
            "Starting epoch 13\n",
            "[13/100][0/157]\tTrain Reconstruction Loss 0.0211\t Train Correlation Loss 1.3004\n",
            "[13/100][50/157]\tTrain Reconstruction Loss 0.0208\t Train Correlation Loss 1.3058\n",
            "[13/100][100/157]\tTrain Reconstruction Loss 0.0211\t Train Correlation Loss 1.3016\n",
            "[13/100][150/157]\tTrain Reconstruction Loss 0.0215\t Train Correlation Loss 1.2872\n",
            "Val Reconstruction Loss 0.0215\t Val Correlation Loss 1.3066\n",
            "Starting epoch 14\n",
            "[14/100][0/157]\tTrain Reconstruction Loss 0.0211\t Train Correlation Loss 1.3072\n",
            "[14/100][50/157]\tTrain Reconstruction Loss 0.0220\t Train Correlation Loss 1.3012\n",
            "[14/100][100/157]\tTrain Reconstruction Loss 0.0217\t Train Correlation Loss 1.2858\n",
            "[14/100][150/157]\tTrain Reconstruction Loss 0.0215\t Train Correlation Loss 1.2974\n",
            "Val Reconstruction Loss 0.0213\t Val Correlation Loss 1.2949\n",
            "Starting epoch 15\n",
            "[15/100][0/157]\tTrain Reconstruction Loss 0.0208\t Train Correlation Loss 1.2956\n",
            "[15/100][50/157]\tTrain Reconstruction Loss 0.0218\t Train Correlation Loss 1.2930\n",
            "[15/100][100/157]\tTrain Reconstruction Loss 0.0212\t Train Correlation Loss 1.2880\n",
            "[15/100][150/157]\tTrain Reconstruction Loss 0.0225\t Train Correlation Loss 1.2772\n",
            "Val Reconstruction Loss 0.0217\t Val Correlation Loss 1.2886\n",
            "Starting epoch 16\n",
            "[16/100][0/157]\tTrain Reconstruction Loss 0.0216\t Train Correlation Loss 1.2855\n",
            "[16/100][50/157]\tTrain Reconstruction Loss 0.0221\t Train Correlation Loss 1.2635\n",
            "[16/100][100/157]\tTrain Reconstruction Loss 0.0225\t Train Correlation Loss 1.2766\n",
            "[16/100][150/157]\tTrain Reconstruction Loss 0.0228\t Train Correlation Loss 1.2753\n",
            "Val Reconstruction Loss 0.0222\t Val Correlation Loss 1.2829\n",
            "Starting epoch 17\n",
            "[17/100][0/157]\tTrain Reconstruction Loss 0.0224\t Train Correlation Loss 1.2872\n",
            "[17/100][50/157]\tTrain Reconstruction Loss 0.0220\t Train Correlation Loss 1.2761\n",
            "[17/100][100/157]\tTrain Reconstruction Loss 0.0223\t Train Correlation Loss 1.2793\n",
            "[17/100][150/157]\tTrain Reconstruction Loss 0.0232\t Train Correlation Loss 1.2804\n",
            "Val Reconstruction Loss 0.0229\t Val Correlation Loss 1.2797\n",
            "Starting epoch 18\n",
            "[18/100][0/157]\tTrain Reconstruction Loss 0.0219\t Train Correlation Loss 1.2727\n",
            "[18/100][50/157]\tTrain Reconstruction Loss 0.0229\t Train Correlation Loss 1.2628\n",
            "[18/100][100/157]\tTrain Reconstruction Loss 0.0234\t Train Correlation Loss 1.2922\n",
            "[18/100][150/157]\tTrain Reconstruction Loss 0.0235\t Train Correlation Loss 1.2711\n",
            "Val Reconstruction Loss 0.0230\t Val Correlation Loss 1.2726\n",
            "Starting epoch 19\n",
            "[19/100][0/157]\tTrain Reconstruction Loss 0.0223\t Train Correlation Loss 1.2532\n",
            "[19/100][50/157]\tTrain Reconstruction Loss 0.0227\t Train Correlation Loss 1.2652\n",
            "[19/100][100/157]\tTrain Reconstruction Loss 0.0230\t Train Correlation Loss 1.2579\n",
            "[19/100][150/157]\tTrain Reconstruction Loss 0.0235\t Train Correlation Loss 1.2630\n",
            "Val Reconstruction Loss 0.0237\t Val Correlation Loss 1.2716\n",
            "Starting epoch 20\n",
            "[20/100][0/157]\tTrain Reconstruction Loss 0.0241\t Train Correlation Loss 1.2635\n",
            "[20/100][50/157]\tTrain Reconstruction Loss 0.0232\t Train Correlation Loss 1.2718\n",
            "[20/100][100/157]\tTrain Reconstruction Loss 0.0231\t Train Correlation Loss 1.2610\n",
            "[20/100][150/157]\tTrain Reconstruction Loss 0.0235\t Train Correlation Loss 1.2653\n",
            "Val Reconstruction Loss 0.0240\t Val Correlation Loss 1.2686\n",
            "Starting epoch 21\n",
            "[21/100][0/157]\tTrain Reconstruction Loss 0.0248\t Train Correlation Loss 1.2599\n",
            "[21/100][50/157]\tTrain Reconstruction Loss 0.0234\t Train Correlation Loss 1.2528\n",
            "[21/100][100/157]\tTrain Reconstruction Loss 0.0235\t Train Correlation Loss 1.2720\n",
            "[21/100][150/157]\tTrain Reconstruction Loss 0.0237\t Train Correlation Loss 1.2613\n",
            "Val Reconstruction Loss 0.0240\t Val Correlation Loss 1.2625\n",
            "Starting epoch 22\n",
            "[22/100][0/157]\tTrain Reconstruction Loss 0.0251\t Train Correlation Loss 1.2609\n",
            "[22/100][50/157]\tTrain Reconstruction Loss 0.0233\t Train Correlation Loss 1.2601\n",
            "[22/100][100/157]\tTrain Reconstruction Loss 0.0247\t Train Correlation Loss 1.2507\n",
            "[22/100][150/157]\tTrain Reconstruction Loss 0.0240\t Train Correlation Loss 1.2492\n",
            "Val Reconstruction Loss 0.0240\t Val Correlation Loss 1.2587\n",
            "Starting epoch 23\n",
            "[23/100][0/157]\tTrain Reconstruction Loss 0.0237\t Train Correlation Loss 1.2665\n",
            "[23/100][50/157]\tTrain Reconstruction Loss 0.0240\t Train Correlation Loss 1.2602\n",
            "[23/100][100/157]\tTrain Reconstruction Loss 0.0241\t Train Correlation Loss 1.2628\n",
            "[23/100][150/157]\tTrain Reconstruction Loss 0.0246\t Train Correlation Loss 1.2469\n",
            "Val Reconstruction Loss 0.0242\t Val Correlation Loss 1.2559\n",
            "Starting epoch 24\n",
            "[24/100][0/157]\tTrain Reconstruction Loss 0.0248\t Train Correlation Loss 1.2676\n",
            "[24/100][50/157]\tTrain Reconstruction Loss 0.0243\t Train Correlation Loss 1.2547\n",
            "[24/100][100/157]\tTrain Reconstruction Loss 0.0245\t Train Correlation Loss 1.2422\n",
            "[24/100][150/157]\tTrain Reconstruction Loss 0.0255\t Train Correlation Loss 1.2399\n",
            "Val Reconstruction Loss 0.0246\t Val Correlation Loss 1.2567\n",
            "Starting epoch 25\n",
            "[25/100][0/157]\tTrain Reconstruction Loss 0.0253\t Train Correlation Loss 1.2581\n",
            "[25/100][50/157]\tTrain Reconstruction Loss 0.0246\t Train Correlation Loss 1.2432\n",
            "[25/100][100/157]\tTrain Reconstruction Loss 0.0236\t Train Correlation Loss 1.2426\n",
            "[25/100][150/157]\tTrain Reconstruction Loss 0.0245\t Train Correlation Loss 1.2490\n",
            "Val Reconstruction Loss 0.0247\t Val Correlation Loss 1.2499\n",
            "Starting epoch 26\n",
            "[26/100][0/157]\tTrain Reconstruction Loss 0.0241\t Train Correlation Loss 1.2514\n",
            "[26/100][50/157]\tTrain Reconstruction Loss 0.0246\t Train Correlation Loss 1.2485\n",
            "[26/100][100/157]\tTrain Reconstruction Loss 0.0246\t Train Correlation Loss 1.2511\n",
            "[26/100][150/157]\tTrain Reconstruction Loss 0.0249\t Train Correlation Loss 1.2387\n",
            "Val Reconstruction Loss 0.0248\t Val Correlation Loss 1.2488\n",
            "Starting epoch 27\n",
            "[27/100][0/157]\tTrain Reconstruction Loss 0.0237\t Train Correlation Loss 1.2419\n",
            "[27/100][50/157]\tTrain Reconstruction Loss 0.0255\t Train Correlation Loss 1.2466\n",
            "[27/100][100/157]\tTrain Reconstruction Loss 0.0250\t Train Correlation Loss 1.2476\n",
            "[27/100][150/157]\tTrain Reconstruction Loss 0.0259\t Train Correlation Loss 1.2416\n",
            "Val Reconstruction Loss 0.0251\t Val Correlation Loss 1.2501\n",
            "Starting epoch 28\n",
            "[28/100][0/157]\tTrain Reconstruction Loss 0.0261\t Train Correlation Loss 1.2519\n",
            "[28/100][50/157]\tTrain Reconstruction Loss 0.0250\t Train Correlation Loss 1.2437\n",
            "[28/100][100/157]\tTrain Reconstruction Loss 0.0248\t Train Correlation Loss 1.2484\n",
            "[28/100][150/157]\tTrain Reconstruction Loss 0.0254\t Train Correlation Loss 1.2505\n",
            "Val Reconstruction Loss 0.0250\t Val Correlation Loss 1.2454\n",
            "Starting epoch 29\n",
            "[29/100][0/157]\tTrain Reconstruction Loss 0.0249\t Train Correlation Loss 1.2467\n",
            "[29/100][50/157]\tTrain Reconstruction Loss 0.0259\t Train Correlation Loss 1.2381\n",
            "[29/100][100/157]\tTrain Reconstruction Loss 0.0249\t Train Correlation Loss 1.2300\n",
            "[29/100][150/157]\tTrain Reconstruction Loss 0.0247\t Train Correlation Loss 1.2448\n",
            "Val Reconstruction Loss 0.0250\t Val Correlation Loss 1.2437\n",
            "Starting epoch 30\n",
            "[30/100][0/157]\tTrain Reconstruction Loss 0.0257\t Train Correlation Loss 1.2302\n",
            "[30/100][50/157]\tTrain Reconstruction Loss 0.0255\t Train Correlation Loss 1.2348\n",
            "[30/100][100/157]\tTrain Reconstruction Loss 0.0258\t Train Correlation Loss 1.2260\n",
            "[30/100][150/157]\tTrain Reconstruction Loss 0.0260\t Train Correlation Loss 1.2374\n",
            "Val Reconstruction Loss 0.0251\t Val Correlation Loss 1.2421\n",
            "Starting epoch 31\n",
            "[31/100][0/157]\tTrain Reconstruction Loss 0.0257\t Train Correlation Loss 1.2436\n",
            "[31/100][50/157]\tTrain Reconstruction Loss 0.0256\t Train Correlation Loss 1.2409\n",
            "[31/100][100/157]\tTrain Reconstruction Loss 0.0250\t Train Correlation Loss 1.2400\n",
            "[31/100][150/157]\tTrain Reconstruction Loss 0.0258\t Train Correlation Loss 1.2251\n",
            "Val Reconstruction Loss 0.0253\t Val Correlation Loss 1.2406\n",
            "Starting epoch 32\n",
            "[32/100][0/157]\tTrain Reconstruction Loss 0.0265\t Train Correlation Loss 1.2214\n",
            "[32/100][50/157]\tTrain Reconstruction Loss 0.0253\t Train Correlation Loss 1.2469\n",
            "[32/100][100/157]\tTrain Reconstruction Loss 0.0247\t Train Correlation Loss 1.2574\n",
            "[32/100][150/157]\tTrain Reconstruction Loss 0.0260\t Train Correlation Loss 1.2289\n",
            "Val Reconstruction Loss 0.0253\t Val Correlation Loss 1.2400\n",
            "Starting epoch 33\n",
            "[33/100][0/157]\tTrain Reconstruction Loss 0.0263\t Train Correlation Loss 1.2232\n",
            "[33/100][50/157]\tTrain Reconstruction Loss 0.0260\t Train Correlation Loss 1.2410\n",
            "[33/100][100/157]\tTrain Reconstruction Loss 0.0249\t Train Correlation Loss 1.2436\n",
            "[33/100][150/157]\tTrain Reconstruction Loss 0.0249\t Train Correlation Loss 1.2303\n",
            "Val Reconstruction Loss 0.0252\t Val Correlation Loss 1.2375\n",
            "Starting epoch 34\n",
            "[34/100][0/157]\tTrain Reconstruction Loss 0.0252\t Train Correlation Loss 1.2211\n",
            "[34/100][50/157]\tTrain Reconstruction Loss 0.0253\t Train Correlation Loss 1.2260\n",
            "[34/100][100/157]\tTrain Reconstruction Loss 0.0246\t Train Correlation Loss 1.2342\n",
            "[34/100][150/157]\tTrain Reconstruction Loss 0.0268\t Train Correlation Loss 1.2358\n",
            "Val Reconstruction Loss 0.0256\t Val Correlation Loss 1.2382\n",
            "Starting epoch 35\n",
            "[35/100][0/157]\tTrain Reconstruction Loss 0.0257\t Train Correlation Loss 1.2439\n",
            "[35/100][50/157]\tTrain Reconstruction Loss 0.0246\t Train Correlation Loss 1.2285\n",
            "[35/100][100/157]\tTrain Reconstruction Loss 0.0264\t Train Correlation Loss 1.2337\n",
            "[35/100][150/157]\tTrain Reconstruction Loss 0.0259\t Train Correlation Loss 1.2281\n",
            "Val Reconstruction Loss 0.0258\t Val Correlation Loss 1.2358\n",
            "Starting epoch 36\n",
            "[36/100][0/157]\tTrain Reconstruction Loss 0.0257\t Train Correlation Loss 1.2396\n",
            "[36/100][50/157]\tTrain Reconstruction Loss 0.0255\t Train Correlation Loss 1.2336\n",
            "[36/100][100/157]\tTrain Reconstruction Loss 0.0258\t Train Correlation Loss 1.2293\n",
            "[36/100][150/157]\tTrain Reconstruction Loss 0.0246\t Train Correlation Loss 1.2362\n",
            "Val Reconstruction Loss 0.0258\t Val Correlation Loss 1.2397\n",
            "Starting epoch 37\n",
            "[37/100][0/157]\tTrain Reconstruction Loss 0.0266\t Train Correlation Loss 1.2381\n",
            "[37/100][50/157]\tTrain Reconstruction Loss 0.0246\t Train Correlation Loss 1.2530\n",
            "[37/100][100/157]\tTrain Reconstruction Loss 0.0245\t Train Correlation Loss 1.2460\n",
            "[37/100][150/157]\tTrain Reconstruction Loss 0.0255\t Train Correlation Loss 1.2308\n",
            "Val Reconstruction Loss 0.0256\t Val Correlation Loss 1.2323\n",
            "Starting epoch 38\n",
            "[38/100][0/157]\tTrain Reconstruction Loss 0.0267\t Train Correlation Loss 1.2236\n",
            "[38/100][50/157]\tTrain Reconstruction Loss 0.0260\t Train Correlation Loss 1.2241\n",
            "[38/100][100/157]\tTrain Reconstruction Loss 0.0260\t Train Correlation Loss 1.2357\n",
            "[38/100][150/157]\tTrain Reconstruction Loss 0.0264\t Train Correlation Loss 1.2253\n",
            "Val Reconstruction Loss 0.0255\t Val Correlation Loss 1.2316\n",
            "Starting epoch 39\n",
            "[39/100][0/157]\tTrain Reconstruction Loss 0.0254\t Train Correlation Loss 1.2333\n",
            "[39/100][50/157]\tTrain Reconstruction Loss 0.0257\t Train Correlation Loss 1.2247\n",
            "[39/100][100/157]\tTrain Reconstruction Loss 0.0265\t Train Correlation Loss 1.2281\n",
            "[39/100][150/157]\tTrain Reconstruction Loss 0.0259\t Train Correlation Loss 1.2253\n",
            "Val Reconstruction Loss 0.0256\t Val Correlation Loss 1.2307\n",
            "Starting epoch 40\n",
            "[40/100][0/157]\tTrain Reconstruction Loss 0.0256\t Train Correlation Loss 1.2321\n",
            "[40/100][50/157]\tTrain Reconstruction Loss 0.0262\t Train Correlation Loss 1.2344\n",
            "[40/100][100/157]\tTrain Reconstruction Loss 0.0257\t Train Correlation Loss 1.2394\n",
            "[40/100][150/157]\tTrain Reconstruction Loss 0.0262\t Train Correlation Loss 1.2245\n",
            "Val Reconstruction Loss 0.0258\t Val Correlation Loss 1.2291\n",
            "Starting epoch 41\n",
            "[41/100][0/157]\tTrain Reconstruction Loss 0.0258\t Train Correlation Loss 1.2286\n",
            "[41/100][50/157]\tTrain Reconstruction Loss 0.0269\t Train Correlation Loss 1.2430\n",
            "[41/100][100/157]\tTrain Reconstruction Loss 0.0258\t Train Correlation Loss 1.2351\n",
            "[41/100][150/157]\tTrain Reconstruction Loss 0.0262\t Train Correlation Loss 1.2309\n",
            "Val Reconstruction Loss 0.0258\t Val Correlation Loss 1.2282\n",
            "Starting epoch 42\n",
            "[42/100][0/157]\tTrain Reconstruction Loss 0.0261\t Train Correlation Loss 1.2208\n",
            "[42/100][50/157]\tTrain Reconstruction Loss 0.0261\t Train Correlation Loss 1.2269\n",
            "[42/100][100/157]\tTrain Reconstruction Loss 0.0260\t Train Correlation Loss 1.2204\n",
            "[42/100][150/157]\tTrain Reconstruction Loss 0.0263\t Train Correlation Loss 1.2214\n",
            "Val Reconstruction Loss 0.0258\t Val Correlation Loss 1.2267\n",
            "Starting epoch 43\n",
            "[43/100][0/157]\tTrain Reconstruction Loss 0.0252\t Train Correlation Loss 1.2295\n",
            "[43/100][50/157]\tTrain Reconstruction Loss 0.0267\t Train Correlation Loss 1.2301\n",
            "[43/100][100/157]\tTrain Reconstruction Loss 0.0267\t Train Correlation Loss 1.2413\n",
            "[43/100][150/157]\tTrain Reconstruction Loss 0.0255\t Train Correlation Loss 1.2344\n",
            "Val Reconstruction Loss 0.0258\t Val Correlation Loss 1.2263\n",
            "Starting epoch 44\n",
            "[44/100][0/157]\tTrain Reconstruction Loss 0.0261\t Train Correlation Loss 1.2338\n",
            "[44/100][50/157]\tTrain Reconstruction Loss 0.0258\t Train Correlation Loss 1.2286\n",
            "[44/100][100/157]\tTrain Reconstruction Loss 0.0253\t Train Correlation Loss 1.2209\n",
            "[44/100][150/157]\tTrain Reconstruction Loss 0.0262\t Train Correlation Loss 1.2274\n",
            "Val Reconstruction Loss 0.0259\t Val Correlation Loss 1.2237\n",
            "Starting epoch 45\n",
            "[45/100][0/157]\tTrain Reconstruction Loss 0.0263\t Train Correlation Loss 1.2090\n",
            "[45/100][50/157]\tTrain Reconstruction Loss 0.0263\t Train Correlation Loss 1.2289\n",
            "[45/100][100/157]\tTrain Reconstruction Loss 0.0263\t Train Correlation Loss 1.2275\n",
            "[45/100][150/157]\tTrain Reconstruction Loss 0.0259\t Train Correlation Loss 1.2129\n",
            "Val Reconstruction Loss 0.0261\t Val Correlation Loss 1.2265\n",
            "Starting epoch 46\n",
            "[46/100][0/157]\tTrain Reconstruction Loss 0.0252\t Train Correlation Loss 1.2289\n",
            "[46/100][50/157]\tTrain Reconstruction Loss 0.0252\t Train Correlation Loss 1.2156\n",
            "[46/100][100/157]\tTrain Reconstruction Loss 0.0250\t Train Correlation Loss 1.2302\n",
            "[46/100][150/157]\tTrain Reconstruction Loss 0.0263\t Train Correlation Loss 1.2102\n",
            "Val Reconstruction Loss 0.0260\t Val Correlation Loss 1.2218\n",
            "Starting epoch 47\n",
            "[47/100][0/157]\tTrain Reconstruction Loss 0.0265\t Train Correlation Loss 1.2184\n",
            "[47/100][50/157]\tTrain Reconstruction Loss 0.0268\t Train Correlation Loss 1.2151\n",
            "[47/100][100/157]\tTrain Reconstruction Loss 0.0262\t Train Correlation Loss 1.2211\n",
            "[47/100][150/157]\tTrain Reconstruction Loss 0.0259\t Train Correlation Loss 1.2287\n",
            "Val Reconstruction Loss 0.0262\t Val Correlation Loss 1.2202\n",
            "Starting epoch 48\n",
            "[48/100][0/157]\tTrain Reconstruction Loss 0.0265\t Train Correlation Loss 1.2234\n",
            "[48/100][50/157]\tTrain Reconstruction Loss 0.0258\t Train Correlation Loss 1.2156\n",
            "[48/100][100/157]\tTrain Reconstruction Loss 0.0259\t Train Correlation Loss 1.2254\n",
            "[48/100][150/157]\tTrain Reconstruction Loss 0.0269\t Train Correlation Loss 1.2306\n",
            "Val Reconstruction Loss 0.0262\t Val Correlation Loss 1.2196\n",
            "Starting epoch 49\n",
            "[49/100][0/157]\tTrain Reconstruction Loss 0.0267\t Train Correlation Loss 1.2123\n",
            "[49/100][50/157]\tTrain Reconstruction Loss 0.0268\t Train Correlation Loss 1.2225\n",
            "[49/100][100/157]\tTrain Reconstruction Loss 0.0271\t Train Correlation Loss 1.2175\n",
            "[49/100][150/157]\tTrain Reconstruction Loss 0.0254\t Train Correlation Loss 1.2124\n",
            "Val Reconstruction Loss 0.0267\t Val Correlation Loss 1.2199\n",
            "Starting epoch 50\n",
            "[50/100][0/157]\tTrain Reconstruction Loss 0.0263\t Train Correlation Loss 1.2222\n",
            "[50/100][50/157]\tTrain Reconstruction Loss 0.0274\t Train Correlation Loss 1.2117\n",
            "[50/100][100/157]\tTrain Reconstruction Loss 0.0262\t Train Correlation Loss 1.1990\n",
            "[50/100][150/157]\tTrain Reconstruction Loss 0.0263\t Train Correlation Loss 1.2039\n",
            "Val Reconstruction Loss 0.0264\t Val Correlation Loss 1.2180\n",
            "Starting epoch 51\n",
            "[51/100][0/157]\tTrain Reconstruction Loss 0.0259\t Train Correlation Loss 1.2228\n",
            "[51/100][50/157]\tTrain Reconstruction Loss 0.0261\t Train Correlation Loss 1.2176\n",
            "[51/100][100/157]\tTrain Reconstruction Loss 0.0263\t Train Correlation Loss 1.2061\n",
            "[51/100][150/157]\tTrain Reconstruction Loss 0.0255\t Train Correlation Loss 1.2101\n",
            "Val Reconstruction Loss 0.0264\t Val Correlation Loss 1.2165\n",
            "Starting epoch 52\n",
            "[52/100][0/157]\tTrain Reconstruction Loss 0.0271\t Train Correlation Loss 1.2122\n",
            "[52/100][50/157]\tTrain Reconstruction Loss 0.0266\t Train Correlation Loss 1.2202\n",
            "[52/100][100/157]\tTrain Reconstruction Loss 0.0268\t Train Correlation Loss 1.2245\n",
            "[52/100][150/157]\tTrain Reconstruction Loss 0.0266\t Train Correlation Loss 1.2027\n",
            "Val Reconstruction Loss 0.0266\t Val Correlation Loss 1.2155\n",
            "Starting epoch 53\n",
            "[53/100][0/157]\tTrain Reconstruction Loss 0.0281\t Train Correlation Loss 1.2048\n",
            "[53/100][50/157]\tTrain Reconstruction Loss 0.0266\t Train Correlation Loss 1.2262\n",
            "[53/100][100/157]\tTrain Reconstruction Loss 0.0275\t Train Correlation Loss 1.1946\n",
            "[53/100][150/157]\tTrain Reconstruction Loss 0.0264\t Train Correlation Loss 1.2130\n",
            "Val Reconstruction Loss 0.0271\t Val Correlation Loss 1.2150\n",
            "Starting epoch 54\n",
            "[54/100][0/157]\tTrain Reconstruction Loss 0.0268\t Train Correlation Loss 1.2181\n",
            "[54/100][50/157]\tTrain Reconstruction Loss 0.0273\t Train Correlation Loss 1.1910\n",
            "[54/100][100/157]\tTrain Reconstruction Loss 0.0262\t Train Correlation Loss 1.2121\n",
            "[54/100][150/157]\tTrain Reconstruction Loss 0.0275\t Train Correlation Loss 1.2216\n",
            "Val Reconstruction Loss 0.0269\t Val Correlation Loss 1.2116\n",
            "Starting epoch 55\n",
            "[55/100][0/157]\tTrain Reconstruction Loss 0.0274\t Train Correlation Loss 1.2380\n",
            "[55/100][50/157]\tTrain Reconstruction Loss 0.0267\t Train Correlation Loss 1.2048\n",
            "[55/100][100/157]\tTrain Reconstruction Loss 0.0262\t Train Correlation Loss 1.2009\n",
            "[55/100][150/157]\tTrain Reconstruction Loss 0.0278\t Train Correlation Loss 1.2057\n",
            "Val Reconstruction Loss 0.0268\t Val Correlation Loss 1.2102\n",
            "Starting epoch 56\n",
            "[56/100][0/157]\tTrain Reconstruction Loss 0.0269\t Train Correlation Loss 1.2141\n",
            "[56/100][50/157]\tTrain Reconstruction Loss 0.0271\t Train Correlation Loss 1.2041\n",
            "[56/100][100/157]\tTrain Reconstruction Loss 0.0271\t Train Correlation Loss 1.2013\n",
            "[56/100][150/157]\tTrain Reconstruction Loss 0.0269\t Train Correlation Loss 1.2051\n",
            "Val Reconstruction Loss 0.0269\t Val Correlation Loss 1.2073\n",
            "Starting epoch 57\n",
            "[57/100][0/157]\tTrain Reconstruction Loss 0.0264\t Train Correlation Loss 1.2029\n",
            "[57/100][50/157]\tTrain Reconstruction Loss 0.0275\t Train Correlation Loss 1.2044\n",
            "[57/100][100/157]\tTrain Reconstruction Loss 0.0278\t Train Correlation Loss 1.1846\n",
            "[57/100][150/157]\tTrain Reconstruction Loss 0.0285\t Train Correlation Loss 1.1995\n",
            "Val Reconstruction Loss 0.0272\t Val Correlation Loss 1.2059\n",
            "Starting epoch 58\n",
            "[58/100][0/157]\tTrain Reconstruction Loss 0.0276\t Train Correlation Loss 1.2138\n",
            "[58/100][50/157]\tTrain Reconstruction Loss 0.0277\t Train Correlation Loss 1.2135\n",
            "[58/100][100/157]\tTrain Reconstruction Loss 0.0266\t Train Correlation Loss 1.2006\n",
            "[58/100][150/157]\tTrain Reconstruction Loss 0.0286\t Train Correlation Loss 1.1898\n",
            "Val Reconstruction Loss 0.0272\t Val Correlation Loss 1.2055\n",
            "Starting epoch 59\n",
            "[59/100][0/157]\tTrain Reconstruction Loss 0.0280\t Train Correlation Loss 1.2001\n",
            "[59/100][50/157]\tTrain Reconstruction Loss 0.0281\t Train Correlation Loss 1.1912\n",
            "[59/100][100/157]\tTrain Reconstruction Loss 0.0266\t Train Correlation Loss 1.2051\n",
            "[59/100][150/157]\tTrain Reconstruction Loss 0.0280\t Train Correlation Loss 1.1889\n",
            "Val Reconstruction Loss 0.0274\t Val Correlation Loss 1.2030\n",
            "Starting epoch 60\n",
            "[60/100][0/157]\tTrain Reconstruction Loss 0.0283\t Train Correlation Loss 1.1920\n",
            "[60/100][50/157]\tTrain Reconstruction Loss 0.0278\t Train Correlation Loss 1.2049\n",
            "[60/100][100/157]\tTrain Reconstruction Loss 0.0279\t Train Correlation Loss 1.2045\n",
            "[60/100][150/157]\tTrain Reconstruction Loss 0.0266\t Train Correlation Loss 1.2038\n",
            "Val Reconstruction Loss 0.0273\t Val Correlation Loss 1.2017\n",
            "Starting epoch 61\n",
            "[61/100][0/157]\tTrain Reconstruction Loss 0.0272\t Train Correlation Loss 1.1971\n",
            "[61/100][50/157]\tTrain Reconstruction Loss 0.0277\t Train Correlation Loss 1.2016\n",
            "[61/100][100/157]\tTrain Reconstruction Loss 0.0278\t Train Correlation Loss 1.1932\n",
            "[61/100][150/157]\tTrain Reconstruction Loss 0.0271\t Train Correlation Loss 1.2087\n",
            "Val Reconstruction Loss 0.0275\t Val Correlation Loss 1.2017\n",
            "Starting epoch 62\n",
            "[62/100][0/157]\tTrain Reconstruction Loss 0.0281\t Train Correlation Loss 1.1995\n",
            "[62/100][50/157]\tTrain Reconstruction Loss 0.0270\t Train Correlation Loss 1.1989\n",
            "[62/100][100/157]\tTrain Reconstruction Loss 0.0284\t Train Correlation Loss 1.1960\n",
            "[62/100][150/157]\tTrain Reconstruction Loss 0.0271\t Train Correlation Loss 1.1883\n",
            "Val Reconstruction Loss 0.0278\t Val Correlation Loss 1.1984\n",
            "Starting epoch 63\n",
            "[63/100][0/157]\tTrain Reconstruction Loss 0.0285\t Train Correlation Loss 1.2038\n",
            "[63/100][50/157]\tTrain Reconstruction Loss 0.0281\t Train Correlation Loss 1.1857\n",
            "[63/100][100/157]\tTrain Reconstruction Loss 0.0266\t Train Correlation Loss 1.1899\n",
            "[63/100][150/157]\tTrain Reconstruction Loss 0.0284\t Train Correlation Loss 1.2017\n",
            "Val Reconstruction Loss 0.0277\t Val Correlation Loss 1.1982\n",
            "Starting epoch 64\n",
            "[64/100][0/157]\tTrain Reconstruction Loss 0.0274\t Train Correlation Loss 1.1967\n",
            "[64/100][50/157]\tTrain Reconstruction Loss 0.0278\t Train Correlation Loss 1.1996\n",
            "[64/100][100/157]\tTrain Reconstruction Loss 0.0287\t Train Correlation Loss 1.1793\n",
            "[64/100][150/157]\tTrain Reconstruction Loss 0.0279\t Train Correlation Loss 1.1860\n",
            "Val Reconstruction Loss 0.0283\t Val Correlation Loss 1.1990\n",
            "Starting epoch 65\n",
            "[65/100][0/157]\tTrain Reconstruction Loss 0.0279\t Train Correlation Loss 1.2009\n",
            "[65/100][50/157]\tTrain Reconstruction Loss 0.0284\t Train Correlation Loss 1.1954\n",
            "[65/100][100/157]\tTrain Reconstruction Loss 0.0293\t Train Correlation Loss 1.1871\n",
            "[65/100][150/157]\tTrain Reconstruction Loss 0.0285\t Train Correlation Loss 1.1886\n",
            "Val Reconstruction Loss 0.0279\t Val Correlation Loss 1.1935\n",
            "Starting epoch 66\n",
            "[66/100][0/157]\tTrain Reconstruction Loss 0.0281\t Train Correlation Loss 1.1800\n",
            "[66/100][50/157]\tTrain Reconstruction Loss 0.0278\t Train Correlation Loss 1.1869\n",
            "[66/100][100/157]\tTrain Reconstruction Loss 0.0279\t Train Correlation Loss 1.1978\n",
            "[66/100][150/157]\tTrain Reconstruction Loss 0.0282\t Train Correlation Loss 1.1910\n",
            "Val Reconstruction Loss 0.0286\t Val Correlation Loss 1.1976\n",
            "Starting epoch 67\n",
            "[67/100][0/157]\tTrain Reconstruction Loss 0.0283\t Train Correlation Loss 1.1897\n",
            "[67/100][50/157]\tTrain Reconstruction Loss 0.0280\t Train Correlation Loss 1.2040\n",
            "[67/100][100/157]\tTrain Reconstruction Loss 0.0282\t Train Correlation Loss 1.2010\n",
            "[67/100][150/157]\tTrain Reconstruction Loss 0.0291\t Train Correlation Loss 1.1902\n",
            "Val Reconstruction Loss 0.0282\t Val Correlation Loss 1.1905\n",
            "Starting epoch 68\n",
            "[68/100][0/157]\tTrain Reconstruction Loss 0.0278\t Train Correlation Loss 1.1858\n",
            "[68/100][50/157]\tTrain Reconstruction Loss 0.0283\t Train Correlation Loss 1.1864\n",
            "[68/100][100/157]\tTrain Reconstruction Loss 0.0285\t Train Correlation Loss 1.1872\n",
            "[68/100][150/157]\tTrain Reconstruction Loss 0.0283\t Train Correlation Loss 1.1941\n",
            "Val Reconstruction Loss 0.0284\t Val Correlation Loss 1.1890\n",
            "Starting epoch 69\n",
            "[69/100][0/157]\tTrain Reconstruction Loss 0.0283\t Train Correlation Loss 1.1917\n",
            "[69/100][50/157]\tTrain Reconstruction Loss 0.0287\t Train Correlation Loss 1.2025\n",
            "[69/100][100/157]\tTrain Reconstruction Loss 0.0289\t Train Correlation Loss 1.1843\n",
            "[69/100][150/157]\tTrain Reconstruction Loss 0.0284\t Train Correlation Loss 1.1935\n",
            "Val Reconstruction Loss 0.0286\t Val Correlation Loss 1.1892\n",
            "Starting epoch 70\n",
            "[70/100][0/157]\tTrain Reconstruction Loss 0.0288\t Train Correlation Loss 1.1869\n",
            "[70/100][50/157]\tTrain Reconstruction Loss 0.0281\t Train Correlation Loss 1.1892\n",
            "[70/100][100/157]\tTrain Reconstruction Loss 0.0285\t Train Correlation Loss 1.1964\n",
            "[70/100][150/157]\tTrain Reconstruction Loss 0.0292\t Train Correlation Loss 1.1930\n",
            "Val Reconstruction Loss 0.0287\t Val Correlation Loss 1.1842\n",
            "Starting epoch 71\n",
            "[71/100][0/157]\tTrain Reconstruction Loss 0.0286\t Train Correlation Loss 1.1913\n",
            "[71/100][50/157]\tTrain Reconstruction Loss 0.0286\t Train Correlation Loss 1.1793\n",
            "[71/100][100/157]\tTrain Reconstruction Loss 0.0289\t Train Correlation Loss 1.1742\n",
            "[71/100][150/157]\tTrain Reconstruction Loss 0.0285\t Train Correlation Loss 1.1855\n",
            "Val Reconstruction Loss 0.0291\t Val Correlation Loss 1.1878\n",
            "Starting epoch 72\n",
            "[72/100][0/157]\tTrain Reconstruction Loss 0.0292\t Train Correlation Loss 1.1849\n",
            "[72/100][50/157]\tTrain Reconstruction Loss 0.0282\t Train Correlation Loss 1.1844\n",
            "[72/100][100/157]\tTrain Reconstruction Loss 0.0297\t Train Correlation Loss 1.1827\n",
            "[72/100][150/157]\tTrain Reconstruction Loss 0.0277\t Train Correlation Loss 1.1801\n",
            "Val Reconstruction Loss 0.0289\t Val Correlation Loss 1.1810\n",
            "Starting epoch 73\n",
            "[73/100][0/157]\tTrain Reconstruction Loss 0.0287\t Train Correlation Loss 1.1822\n",
            "[73/100][50/157]\tTrain Reconstruction Loss 0.0283\t Train Correlation Loss 1.1797\n",
            "[73/100][100/157]\tTrain Reconstruction Loss 0.0298\t Train Correlation Loss 1.1886\n",
            "[73/100][150/157]\tTrain Reconstruction Loss 0.0286\t Train Correlation Loss 1.1621\n",
            "Val Reconstruction Loss 0.0293\t Val Correlation Loss 1.1824\n",
            "Starting epoch 74\n",
            "[74/100][0/157]\tTrain Reconstruction Loss 0.0282\t Train Correlation Loss 1.1783\n",
            "[74/100][50/157]\tTrain Reconstruction Loss 0.0288\t Train Correlation Loss 1.1783\n",
            "[74/100][100/157]\tTrain Reconstruction Loss 0.0290\t Train Correlation Loss 1.1655\n",
            "[74/100][150/157]\tTrain Reconstruction Loss 0.0290\t Train Correlation Loss 1.1805\n",
            "Val Reconstruction Loss 0.0296\t Val Correlation Loss 1.1794\n",
            "Starting epoch 75\n",
            "[75/100][0/157]\tTrain Reconstruction Loss 0.0284\t Train Correlation Loss 1.1769\n",
            "[75/100][50/157]\tTrain Reconstruction Loss 0.0277\t Train Correlation Loss 1.1877\n",
            "[75/100][100/157]\tTrain Reconstruction Loss 0.0305\t Train Correlation Loss 1.1707\n",
            "[75/100][150/157]\tTrain Reconstruction Loss 0.0304\t Train Correlation Loss 1.1573\n",
            "Val Reconstruction Loss 0.0293\t Val Correlation Loss 1.1756\n",
            "Starting epoch 76\n",
            "[76/100][0/157]\tTrain Reconstruction Loss 0.0293\t Train Correlation Loss 1.1616\n",
            "[76/100][50/157]\tTrain Reconstruction Loss 0.0283\t Train Correlation Loss 1.1648\n",
            "[76/100][100/157]\tTrain Reconstruction Loss 0.0305\t Train Correlation Loss 1.1634\n",
            "[76/100][150/157]\tTrain Reconstruction Loss 0.0300\t Train Correlation Loss 1.1675\n",
            "Val Reconstruction Loss 0.0295\t Val Correlation Loss 1.1729\n",
            "Starting epoch 77\n",
            "[77/100][0/157]\tTrain Reconstruction Loss 0.0294\t Train Correlation Loss 1.1735\n",
            "[77/100][50/157]\tTrain Reconstruction Loss 0.0323\t Train Correlation Loss 1.1685\n",
            "[77/100][100/157]\tTrain Reconstruction Loss 0.0298\t Train Correlation Loss 1.1589\n",
            "[77/100][150/157]\tTrain Reconstruction Loss 0.0297\t Train Correlation Loss 1.1663\n",
            "Val Reconstruction Loss 0.0297\t Val Correlation Loss 1.1717\n",
            "Starting epoch 78\n",
            "[78/100][0/157]\tTrain Reconstruction Loss 0.0287\t Train Correlation Loss 1.1779\n",
            "[78/100][50/157]\tTrain Reconstruction Loss 0.0308\t Train Correlation Loss 1.1613\n",
            "[78/100][100/157]\tTrain Reconstruction Loss 0.0299\t Train Correlation Loss 1.1795\n",
            "[78/100][150/157]\tTrain Reconstruction Loss 0.0308\t Train Correlation Loss 1.1647\n",
            "Val Reconstruction Loss 0.0298\t Val Correlation Loss 1.1695\n",
            "Starting epoch 79\n",
            "[79/100][0/157]\tTrain Reconstruction Loss 0.0297\t Train Correlation Loss 1.1669\n",
            "[79/100][50/157]\tTrain Reconstruction Loss 0.0291\t Train Correlation Loss 1.1691\n",
            "[79/100][100/157]\tTrain Reconstruction Loss 0.0307\t Train Correlation Loss 1.1476\n",
            "[79/100][150/157]\tTrain Reconstruction Loss 0.0293\t Train Correlation Loss 1.1525\n",
            "Val Reconstruction Loss 0.0303\t Val Correlation Loss 1.1718\n",
            "Starting epoch 80\n",
            "[80/100][0/157]\tTrain Reconstruction Loss 0.0298\t Train Correlation Loss 1.1806\n",
            "[80/100][50/157]\tTrain Reconstruction Loss 0.0296\t Train Correlation Loss 1.1757\n",
            "[80/100][100/157]\tTrain Reconstruction Loss 0.0299\t Train Correlation Loss 1.1655\n",
            "[80/100][150/157]\tTrain Reconstruction Loss 0.0306\t Train Correlation Loss 1.1569\n",
            "Val Reconstruction Loss 0.0305\t Val Correlation Loss 1.1703\n",
            "Starting epoch 81\n",
            "[81/100][0/157]\tTrain Reconstruction Loss 0.0306\t Train Correlation Loss 1.1578\n",
            "[81/100][50/157]\tTrain Reconstruction Loss 0.0316\t Train Correlation Loss 1.1583\n",
            "[81/100][100/157]\tTrain Reconstruction Loss 0.0294\t Train Correlation Loss 1.1686\n",
            "[81/100][150/157]\tTrain Reconstruction Loss 0.0303\t Train Correlation Loss 1.1733\n",
            "Val Reconstruction Loss 0.0304\t Val Correlation Loss 1.1645\n",
            "Starting epoch 82\n",
            "[82/100][0/157]\tTrain Reconstruction Loss 0.0302\t Train Correlation Loss 1.1534\n",
            "[82/100][50/157]\tTrain Reconstruction Loss 0.0300\t Train Correlation Loss 1.1732\n",
            "[82/100][100/157]\tTrain Reconstruction Loss 0.0312\t Train Correlation Loss 1.1460\n",
            "[82/100][150/157]\tTrain Reconstruction Loss 0.0301\t Train Correlation Loss 1.1689\n",
            "Val Reconstruction Loss 0.0308\t Val Correlation Loss 1.1643\n",
            "Starting epoch 83\n",
            "[83/100][0/157]\tTrain Reconstruction Loss 0.0309\t Train Correlation Loss 1.1585\n",
            "[83/100][50/157]\tTrain Reconstruction Loss 0.0316\t Train Correlation Loss 1.1660\n",
            "[83/100][100/157]\tTrain Reconstruction Loss 0.0303\t Train Correlation Loss 1.1590\n",
            "[83/100][150/157]\tTrain Reconstruction Loss 0.0298\t Train Correlation Loss 1.1687\n",
            "Val Reconstruction Loss 0.0310\t Val Correlation Loss 1.1677\n",
            "Starting epoch 84\n",
            "[84/100][0/157]\tTrain Reconstruction Loss 0.0312\t Train Correlation Loss 1.1628\n",
            "[84/100][50/157]\tTrain Reconstruction Loss 0.0305\t Train Correlation Loss 1.1617\n",
            "[84/100][100/157]\tTrain Reconstruction Loss 0.0305\t Train Correlation Loss 1.1646\n",
            "[84/100][150/157]\tTrain Reconstruction Loss 0.0306\t Train Correlation Loss 1.1626\n",
            "Val Reconstruction Loss 0.0308\t Val Correlation Loss 1.1579\n",
            "Starting epoch 85\n",
            "[85/100][0/157]\tTrain Reconstruction Loss 0.0307\t Train Correlation Loss 1.1468\n",
            "[85/100][50/157]\tTrain Reconstruction Loss 0.0310\t Train Correlation Loss 1.1599\n",
            "[85/100][100/157]\tTrain Reconstruction Loss 0.0312\t Train Correlation Loss 1.1522\n",
            "[85/100][150/157]\tTrain Reconstruction Loss 0.0309\t Train Correlation Loss 1.1588\n",
            "Val Reconstruction Loss 0.0310\t Val Correlation Loss 1.1559\n",
            "Starting epoch 86\n",
            "[86/100][0/157]\tTrain Reconstruction Loss 0.0318\t Train Correlation Loss 1.1520\n",
            "[86/100][50/157]\tTrain Reconstruction Loss 0.0315\t Train Correlation Loss 1.1650\n",
            "[86/100][100/157]\tTrain Reconstruction Loss 0.0315\t Train Correlation Loss 1.1489\n",
            "[86/100][150/157]\tTrain Reconstruction Loss 0.0308\t Train Correlation Loss 1.1593\n",
            "Val Reconstruction Loss 0.0312\t Val Correlation Loss 1.1542\n",
            "Starting epoch 87\n",
            "[87/100][0/157]\tTrain Reconstruction Loss 0.0307\t Train Correlation Loss 1.1482\n",
            "[87/100][50/157]\tTrain Reconstruction Loss 0.0306\t Train Correlation Loss 1.1658\n",
            "[87/100][100/157]\tTrain Reconstruction Loss 0.0313\t Train Correlation Loss 1.1370\n",
            "[87/100][150/157]\tTrain Reconstruction Loss 0.0322\t Train Correlation Loss 1.1452\n",
            "Val Reconstruction Loss 0.0313\t Val Correlation Loss 1.1528\n",
            "Starting epoch 88\n",
            "[88/100][0/157]\tTrain Reconstruction Loss 0.0333\t Train Correlation Loss 1.1396\n",
            "[88/100][50/157]\tTrain Reconstruction Loss 0.0306\t Train Correlation Loss 1.1414\n",
            "[88/100][100/157]\tTrain Reconstruction Loss 0.0324\t Train Correlation Loss 1.1424\n",
            "[88/100][150/157]\tTrain Reconstruction Loss 0.0324\t Train Correlation Loss 1.1398\n",
            "Val Reconstruction Loss 0.0315\t Val Correlation Loss 1.1509\n",
            "Starting epoch 89\n",
            "[89/100][0/157]\tTrain Reconstruction Loss 0.0323\t Train Correlation Loss 1.1436\n",
            "[89/100][50/157]\tTrain Reconstruction Loss 0.0304\t Train Correlation Loss 1.1492\n",
            "[89/100][100/157]\tTrain Reconstruction Loss 0.0324\t Train Correlation Loss 1.1402\n",
            "[89/100][150/157]\tTrain Reconstruction Loss 0.0325\t Train Correlation Loss 1.1476\n",
            "Val Reconstruction Loss 0.0318\t Val Correlation Loss 1.1554\n",
            "Starting epoch 90\n",
            "[90/100][0/157]\tTrain Reconstruction Loss 0.0324\t Train Correlation Loss 1.1495\n",
            "[90/100][50/157]\tTrain Reconstruction Loss 0.0329\t Train Correlation Loss 1.1380\n",
            "[90/100][100/157]\tTrain Reconstruction Loss 0.0312\t Train Correlation Loss 1.1424\n",
            "[90/100][150/157]\tTrain Reconstruction Loss 0.0315\t Train Correlation Loss 1.1543\n",
            "Val Reconstruction Loss 0.0321\t Val Correlation Loss 1.1524\n",
            "Starting epoch 91\n",
            "[91/100][0/157]\tTrain Reconstruction Loss 0.0332\t Train Correlation Loss 1.1335\n",
            "[91/100][50/157]\tTrain Reconstruction Loss 0.0326\t Train Correlation Loss 1.1408\n",
            "[91/100][100/157]\tTrain Reconstruction Loss 0.0312\t Train Correlation Loss 1.1560\n",
            "[91/100][150/157]\tTrain Reconstruction Loss 0.0316\t Train Correlation Loss 1.1339\n",
            "Val Reconstruction Loss 0.0318\t Val Correlation Loss 1.1462\n",
            "Starting epoch 92\n",
            "[92/100][0/157]\tTrain Reconstruction Loss 0.0319\t Train Correlation Loss 1.1502\n",
            "[92/100][50/157]\tTrain Reconstruction Loss 0.0305\t Train Correlation Loss 1.1411\n",
            "[92/100][100/157]\tTrain Reconstruction Loss 0.0323\t Train Correlation Loss 1.1499\n",
            "[92/100][150/157]\tTrain Reconstruction Loss 0.0325\t Train Correlation Loss 1.1327\n",
            "Val Reconstruction Loss 0.0321\t Val Correlation Loss 1.1448\n",
            "Starting epoch 93\n",
            "[93/100][0/157]\tTrain Reconstruction Loss 0.0326\t Train Correlation Loss 1.1453\n",
            "[93/100][50/157]\tTrain Reconstruction Loss 0.0326\t Train Correlation Loss 1.1402\n",
            "[93/100][100/157]\tTrain Reconstruction Loss 0.0336\t Train Correlation Loss 1.1381\n",
            "[93/100][150/157]\tTrain Reconstruction Loss 0.0322\t Train Correlation Loss 1.1362\n",
            "Val Reconstruction Loss 0.0322\t Val Correlation Loss 1.1449\n",
            "Starting epoch 94\n",
            "[94/100][0/157]\tTrain Reconstruction Loss 0.0323\t Train Correlation Loss 1.1421\n",
            "[94/100][50/157]\tTrain Reconstruction Loss 0.0327\t Train Correlation Loss 1.1440\n",
            "[94/100][100/157]\tTrain Reconstruction Loss 0.0318\t Train Correlation Loss 1.1315\n",
            "[94/100][150/157]\tTrain Reconstruction Loss 0.0325\t Train Correlation Loss 1.1470\n",
            "Val Reconstruction Loss 0.0323\t Val Correlation Loss 1.1428\n",
            "Starting epoch 95\n",
            "[95/100][0/157]\tTrain Reconstruction Loss 0.0314\t Train Correlation Loss 1.1394\n",
            "[95/100][50/157]\tTrain Reconstruction Loss 0.0325\t Train Correlation Loss 1.1525\n",
            "[95/100][100/157]\tTrain Reconstruction Loss 0.0332\t Train Correlation Loss 1.1451\n",
            "[95/100][150/157]\tTrain Reconstruction Loss 0.0316\t Train Correlation Loss 1.1383\n",
            "Val Reconstruction Loss 0.0328\t Val Correlation Loss 1.1434\n",
            "Starting epoch 96\n",
            "[96/100][0/157]\tTrain Reconstruction Loss 0.0332\t Train Correlation Loss 1.1328\n",
            "[96/100][50/157]\tTrain Reconstruction Loss 0.0320\t Train Correlation Loss 1.1409\n",
            "[96/100][100/157]\tTrain Reconstruction Loss 0.0328\t Train Correlation Loss 1.1227\n",
            "[96/100][150/157]\tTrain Reconstruction Loss 0.0318\t Train Correlation Loss 1.1369\n",
            "Val Reconstruction Loss 0.0327\t Val Correlation Loss 1.1405\n",
            "Starting epoch 97\n",
            "[97/100][0/157]\tTrain Reconstruction Loss 0.0320\t Train Correlation Loss 1.1298\n",
            "[97/100][50/157]\tTrain Reconstruction Loss 0.0325\t Train Correlation Loss 1.1244\n",
            "[97/100][100/157]\tTrain Reconstruction Loss 0.0323\t Train Correlation Loss 1.1412\n",
            "[97/100][150/157]\tTrain Reconstruction Loss 0.0335\t Train Correlation Loss 1.1471\n",
            "Val Reconstruction Loss 0.0329\t Val Correlation Loss 1.1406\n",
            "Starting epoch 98\n",
            "[98/100][0/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.1394\n",
            "[98/100][50/157]\tTrain Reconstruction Loss 0.0326\t Train Correlation Loss 1.1225\n",
            "[98/100][100/157]\tTrain Reconstruction Loss 0.0321\t Train Correlation Loss 1.1270\n",
            "[98/100][150/157]\tTrain Reconstruction Loss 0.0327\t Train Correlation Loss 1.1304\n",
            "Val Reconstruction Loss 0.0330\t Val Correlation Loss 1.1390\n",
            "Starting epoch 99\n",
            "[99/100][0/157]\tTrain Reconstruction Loss 0.0335\t Train Correlation Loss 1.1352\n",
            "[99/100][50/157]\tTrain Reconstruction Loss 0.0333\t Train Correlation Loss 1.1348\n",
            "[99/100][100/157]\tTrain Reconstruction Loss 0.0329\t Train Correlation Loss 1.1282\n",
            "[99/100][150/157]\tTrain Reconstruction Loss 0.0319\t Train Correlation Loss 1.1314\n",
            "Val Reconstruction Loss 0.0328\t Val Correlation Loss 1.1341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOuGnzT5hcWP"
      },
      "source": [
        "create_checkpoint()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB_0YP5oryN7",
        "outputId": "eb792189-8472-4420-d2f1-119a718a0a64"
      },
      "source": [
        "train_autoenc(100,150)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[100/150][0/157]\tTrain Reconstruction Loss 0.0329\t Train Correlation Loss 1.1122\n",
            "[100/150][50/157]\tTrain Reconstruction Loss 0.0321\t Train Correlation Loss 1.1391\n",
            "[100/150][100/157]\tTrain Reconstruction Loss 0.0326\t Train Correlation Loss 1.1267\n",
            "[100/150][150/157]\tTrain Reconstruction Loss 0.0315\t Train Correlation Loss 1.1210\n",
            "Val Reconstruction Loss 0.0327\t Val Correlation Loss 1.1319\n",
            "Starting epoch 101\n",
            "[101/150][0/157]\tTrain Reconstruction Loss 0.0328\t Train Correlation Loss 1.1243\n",
            "[101/150][50/157]\tTrain Reconstruction Loss 0.0323\t Train Correlation Loss 1.1427\n",
            "[101/150][100/157]\tTrain Reconstruction Loss 0.0328\t Train Correlation Loss 1.1305\n",
            "[101/150][150/157]\tTrain Reconstruction Loss 0.0328\t Train Correlation Loss 1.1274\n",
            "Val Reconstruction Loss 0.0331\t Val Correlation Loss 1.1345\n",
            "Starting epoch 102\n",
            "[102/150][0/157]\tTrain Reconstruction Loss 0.0325\t Train Correlation Loss 1.1422\n",
            "[102/150][50/157]\tTrain Reconstruction Loss 0.0320\t Train Correlation Loss 1.1355\n",
            "[102/150][100/157]\tTrain Reconstruction Loss 0.0329\t Train Correlation Loss 1.1283\n",
            "[102/150][150/157]\tTrain Reconstruction Loss 0.0342\t Train Correlation Loss 1.1221\n",
            "Val Reconstruction Loss 0.0331\t Val Correlation Loss 1.1279\n",
            "Starting epoch 103\n",
            "[103/150][0/157]\tTrain Reconstruction Loss 0.0332\t Train Correlation Loss 1.1179\n",
            "[103/150][50/157]\tTrain Reconstruction Loss 0.0331\t Train Correlation Loss 1.1247\n",
            "[103/150][100/157]\tTrain Reconstruction Loss 0.0325\t Train Correlation Loss 1.1321\n",
            "[103/150][150/157]\tTrain Reconstruction Loss 0.0340\t Train Correlation Loss 1.1131\n",
            "Val Reconstruction Loss 0.0331\t Val Correlation Loss 1.1301\n",
            "Starting epoch 104\n",
            "[104/150][0/157]\tTrain Reconstruction Loss 0.0333\t Train Correlation Loss 1.1415\n",
            "[104/150][50/157]\tTrain Reconstruction Loss 0.0324\t Train Correlation Loss 1.1156\n",
            "[104/150][100/157]\tTrain Reconstruction Loss 0.0315\t Train Correlation Loss 1.1356\n",
            "[104/150][150/157]\tTrain Reconstruction Loss 0.0331\t Train Correlation Loss 1.1253\n",
            "Val Reconstruction Loss 0.0333\t Val Correlation Loss 1.1249\n",
            "Starting epoch 105\n",
            "[105/150][0/157]\tTrain Reconstruction Loss 0.0332\t Train Correlation Loss 1.1437\n",
            "[105/150][50/157]\tTrain Reconstruction Loss 0.0318\t Train Correlation Loss 1.1302\n",
            "[105/150][100/157]\tTrain Reconstruction Loss 0.0329\t Train Correlation Loss 1.1432\n",
            "[105/150][150/157]\tTrain Reconstruction Loss 0.0343\t Train Correlation Loss 1.1202\n",
            "Val Reconstruction Loss 0.0334\t Val Correlation Loss 1.1238\n",
            "Starting epoch 106\n",
            "[106/150][0/157]\tTrain Reconstruction Loss 0.0335\t Train Correlation Loss 1.1142\n",
            "[106/150][50/157]\tTrain Reconstruction Loss 0.0339\t Train Correlation Loss 1.1287\n",
            "[106/150][100/157]\tTrain Reconstruction Loss 0.0327\t Train Correlation Loss 1.1247\n",
            "[106/150][150/157]\tTrain Reconstruction Loss 0.0331\t Train Correlation Loss 1.1134\n",
            "Val Reconstruction Loss 0.0336\t Val Correlation Loss 1.1227\n",
            "Starting epoch 107\n",
            "[107/150][0/157]\tTrain Reconstruction Loss 0.0353\t Train Correlation Loss 1.1107\n",
            "[107/150][50/157]\tTrain Reconstruction Loss 0.0341\t Train Correlation Loss 1.1062\n",
            "[107/150][100/157]\tTrain Reconstruction Loss 0.0340\t Train Correlation Loss 1.1086\n",
            "[107/150][150/157]\tTrain Reconstruction Loss 0.0337\t Train Correlation Loss 1.1292\n",
            "Val Reconstruction Loss 0.0335\t Val Correlation Loss 1.1211\n",
            "Starting epoch 108\n",
            "[108/150][0/157]\tTrain Reconstruction Loss 0.0347\t Train Correlation Loss 1.1225\n",
            "[108/150][50/157]\tTrain Reconstruction Loss 0.0335\t Train Correlation Loss 1.1107\n",
            "[108/150][100/157]\tTrain Reconstruction Loss 0.0343\t Train Correlation Loss 1.1168\n",
            "[108/150][150/157]\tTrain Reconstruction Loss 0.0333\t Train Correlation Loss 1.1248\n",
            "Val Reconstruction Loss 0.0336\t Val Correlation Loss 1.1203\n",
            "Starting epoch 109\n",
            "[109/150][0/157]\tTrain Reconstruction Loss 0.0336\t Train Correlation Loss 1.1063\n",
            "[109/150][50/157]\tTrain Reconstruction Loss 0.0333\t Train Correlation Loss 1.1167\n",
            "[109/150][100/157]\tTrain Reconstruction Loss 0.0331\t Train Correlation Loss 1.1191\n",
            "[109/150][150/157]\tTrain Reconstruction Loss 0.0349\t Train Correlation Loss 1.1017\n",
            "Val Reconstruction Loss 0.0338\t Val Correlation Loss 1.1183\n",
            "Starting epoch 110\n",
            "[110/150][0/157]\tTrain Reconstruction Loss 0.0324\t Train Correlation Loss 1.1202\n",
            "[110/150][50/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.1070\n",
            "[110/150][100/157]\tTrain Reconstruction Loss 0.0331\t Train Correlation Loss 1.1049\n",
            "[110/150][150/157]\tTrain Reconstruction Loss 0.0342\t Train Correlation Loss 1.1190\n",
            "Val Reconstruction Loss 0.0338\t Val Correlation Loss 1.1174\n",
            "Starting epoch 111\n",
            "[111/150][0/157]\tTrain Reconstruction Loss 0.0326\t Train Correlation Loss 1.1236\n",
            "[111/150][50/157]\tTrain Reconstruction Loss 0.0332\t Train Correlation Loss 1.1144\n",
            "[111/150][100/157]\tTrain Reconstruction Loss 0.0335\t Train Correlation Loss 1.1272\n",
            "[111/150][150/157]\tTrain Reconstruction Loss 0.0338\t Train Correlation Loss 1.1246\n",
            "Val Reconstruction Loss 0.0338\t Val Correlation Loss 1.1166\n",
            "Starting epoch 112\n",
            "[112/150][0/157]\tTrain Reconstruction Loss 0.0336\t Train Correlation Loss 1.1026\n",
            "[112/150][50/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.1207\n",
            "[112/150][100/157]\tTrain Reconstruction Loss 0.0346\t Train Correlation Loss 1.1176\n",
            "[112/150][150/157]\tTrain Reconstruction Loss 0.0336\t Train Correlation Loss 1.1389\n",
            "Val Reconstruction Loss 0.0343\t Val Correlation Loss 1.1178\n",
            "Starting epoch 113\n",
            "[113/150][0/157]\tTrain Reconstruction Loss 0.0328\t Train Correlation Loss 1.1117\n",
            "[113/150][50/157]\tTrain Reconstruction Loss 0.0336\t Train Correlation Loss 1.1195\n",
            "[113/150][100/157]\tTrain Reconstruction Loss 0.0331\t Train Correlation Loss 1.1082\n",
            "[113/150][150/157]\tTrain Reconstruction Loss 0.0352\t Train Correlation Loss 1.1108\n",
            "Val Reconstruction Loss 0.0338\t Val Correlation Loss 1.1153\n",
            "Starting epoch 114\n",
            "[114/150][0/157]\tTrain Reconstruction Loss 0.0319\t Train Correlation Loss 1.1313\n",
            "[114/150][50/157]\tTrain Reconstruction Loss 0.0349\t Train Correlation Loss 1.0961\n",
            "[114/150][100/157]\tTrain Reconstruction Loss 0.0346\t Train Correlation Loss 1.1070\n",
            "[114/150][150/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.1196\n",
            "Val Reconstruction Loss 0.0343\t Val Correlation Loss 1.1127\n",
            "Starting epoch 115\n",
            "[115/150][0/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.1073\n",
            "[115/150][50/157]\tTrain Reconstruction Loss 0.0337\t Train Correlation Loss 1.1073\n",
            "[115/150][100/157]\tTrain Reconstruction Loss 0.0346\t Train Correlation Loss 1.1020\n",
            "[115/150][150/157]\tTrain Reconstruction Loss 0.0336\t Train Correlation Loss 1.1073\n",
            "Val Reconstruction Loss 0.0342\t Val Correlation Loss 1.1112\n",
            "Starting epoch 116\n",
            "[116/150][0/157]\tTrain Reconstruction Loss 0.0337\t Train Correlation Loss 1.1191\n",
            "[116/150][50/157]\tTrain Reconstruction Loss 0.0333\t Train Correlation Loss 1.1183\n",
            "[116/150][100/157]\tTrain Reconstruction Loss 0.0361\t Train Correlation Loss 1.1132\n",
            "[116/150][150/157]\tTrain Reconstruction Loss 0.0343\t Train Correlation Loss 1.1069\n",
            "Val Reconstruction Loss 0.0342\t Val Correlation Loss 1.1114\n",
            "Starting epoch 117\n",
            "[117/150][0/157]\tTrain Reconstruction Loss 0.0340\t Train Correlation Loss 1.1157\n",
            "[117/150][50/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0905\n",
            "[117/150][100/157]\tTrain Reconstruction Loss 0.0346\t Train Correlation Loss 1.1073\n",
            "[117/150][150/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.1015\n",
            "Val Reconstruction Loss 0.0345\t Val Correlation Loss 1.1094\n",
            "Starting epoch 118\n",
            "[118/150][0/157]\tTrain Reconstruction Loss 0.0348\t Train Correlation Loss 1.1003\n",
            "[118/150][50/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.0976\n",
            "[118/150][100/157]\tTrain Reconstruction Loss 0.0327\t Train Correlation Loss 1.1094\n",
            "[118/150][150/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0983\n",
            "Val Reconstruction Loss 0.0345\t Val Correlation Loss 1.1084\n",
            "Starting epoch 119\n",
            "[119/150][0/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.1040\n",
            "[119/150][50/157]\tTrain Reconstruction Loss 0.0334\t Train Correlation Loss 1.1187\n",
            "[119/150][100/157]\tTrain Reconstruction Loss 0.0340\t Train Correlation Loss 1.1175\n",
            "[119/150][150/157]\tTrain Reconstruction Loss 0.0335\t Train Correlation Loss 1.1186\n",
            "Val Reconstruction Loss 0.0343\t Val Correlation Loss 1.1072\n",
            "Starting epoch 120\n",
            "[120/150][0/157]\tTrain Reconstruction Loss 0.0325\t Train Correlation Loss 1.1095\n",
            "[120/150][50/157]\tTrain Reconstruction Loss 0.0333\t Train Correlation Loss 1.1164\n",
            "[120/150][100/157]\tTrain Reconstruction Loss 0.0329\t Train Correlation Loss 1.1158\n",
            "[120/150][150/157]\tTrain Reconstruction Loss 0.0347\t Train Correlation Loss 1.1136\n",
            "Val Reconstruction Loss 0.0345\t Val Correlation Loss 1.1112\n",
            "Starting epoch 121\n",
            "[121/150][0/157]\tTrain Reconstruction Loss 0.0338\t Train Correlation Loss 1.1088\n",
            "[121/150][50/157]\tTrain Reconstruction Loss 0.0332\t Train Correlation Loss 1.1164\n",
            "[121/150][100/157]\tTrain Reconstruction Loss 0.0352\t Train Correlation Loss 1.0939\n",
            "[121/150][150/157]\tTrain Reconstruction Loss 0.0339\t Train Correlation Loss 1.1101\n",
            "Val Reconstruction Loss 0.0346\t Val Correlation Loss 1.1081\n",
            "Starting epoch 122\n",
            "[122/150][0/157]\tTrain Reconstruction Loss 0.0323\t Train Correlation Loss 1.1128\n",
            "[122/150][50/157]\tTrain Reconstruction Loss 0.0337\t Train Correlation Loss 1.1065\n",
            "[122/150][100/157]\tTrain Reconstruction Loss 0.0348\t Train Correlation Loss 1.0984\n",
            "[122/150][150/157]\tTrain Reconstruction Loss 0.0337\t Train Correlation Loss 1.1067\n",
            "Val Reconstruction Loss 0.0347\t Val Correlation Loss 1.1054\n",
            "Starting epoch 123\n",
            "[123/150][0/157]\tTrain Reconstruction Loss 0.0340\t Train Correlation Loss 1.1010\n",
            "[123/150][50/157]\tTrain Reconstruction Loss 0.0349\t Train Correlation Loss 1.1015\n",
            "[123/150][100/157]\tTrain Reconstruction Loss 0.0358\t Train Correlation Loss 1.0936\n",
            "[123/150][150/157]\tTrain Reconstruction Loss 0.0341\t Train Correlation Loss 1.1112\n",
            "Val Reconstruction Loss 0.0348\t Val Correlation Loss 1.1052\n",
            "Starting epoch 124\n",
            "[124/150][0/157]\tTrain Reconstruction Loss 0.0343\t Train Correlation Loss 1.1145\n",
            "[124/150][50/157]\tTrain Reconstruction Loss 0.0352\t Train Correlation Loss 1.1154\n",
            "[124/150][100/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.1077\n",
            "[124/150][150/157]\tTrain Reconstruction Loss 0.0338\t Train Correlation Loss 1.1204\n",
            "Val Reconstruction Loss 0.0347\t Val Correlation Loss 1.1050\n",
            "Starting epoch 125\n",
            "[125/150][0/157]\tTrain Reconstruction Loss 0.0352\t Train Correlation Loss 1.0973\n",
            "[125/150][50/157]\tTrain Reconstruction Loss 0.0349\t Train Correlation Loss 1.1054\n",
            "[125/150][100/157]\tTrain Reconstruction Loss 0.0350\t Train Correlation Loss 1.1090\n",
            "[125/150][150/157]\tTrain Reconstruction Loss 0.0340\t Train Correlation Loss 1.1098\n",
            "Val Reconstruction Loss 0.0346\t Val Correlation Loss 1.1025\n",
            "Starting epoch 126\n",
            "[126/150][0/157]\tTrain Reconstruction Loss 0.0353\t Train Correlation Loss 1.0912\n",
            "[126/150][50/157]\tTrain Reconstruction Loss 0.0343\t Train Correlation Loss 1.0954\n",
            "[126/150][100/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.1000\n",
            "[126/150][150/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.1037\n",
            "Val Reconstruction Loss 0.0347\t Val Correlation Loss 1.1017\n",
            "Starting epoch 127\n",
            "[127/150][0/157]\tTrain Reconstruction Loss 0.0342\t Train Correlation Loss 1.1031\n",
            "[127/150][50/157]\tTrain Reconstruction Loss 0.0341\t Train Correlation Loss 1.1006\n",
            "[127/150][100/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.1040\n",
            "[127/150][150/157]\tTrain Reconstruction Loss 0.0348\t Train Correlation Loss 1.0914\n",
            "Val Reconstruction Loss 0.0345\t Val Correlation Loss 1.1008\n",
            "Starting epoch 128\n",
            "[128/150][0/157]\tTrain Reconstruction Loss 0.0340\t Train Correlation Loss 1.1007\n",
            "[128/150][50/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0902\n",
            "[128/150][100/157]\tTrain Reconstruction Loss 0.0336\t Train Correlation Loss 1.0904\n",
            "[128/150][150/157]\tTrain Reconstruction Loss 0.0349\t Train Correlation Loss 1.1119\n",
            "Val Reconstruction Loss 0.0352\t Val Correlation Loss 1.1050\n",
            "Starting epoch 129\n",
            "[129/150][0/157]\tTrain Reconstruction Loss 0.0359\t Train Correlation Loss 1.1093\n",
            "[129/150][50/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.1034\n",
            "[129/150][100/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0953\n",
            "[129/150][150/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0953\n",
            "Val Reconstruction Loss 0.0350\t Val Correlation Loss 1.1011\n",
            "Starting epoch 130\n",
            "[130/150][0/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0910\n",
            "[130/150][50/157]\tTrain Reconstruction Loss 0.0348\t Train Correlation Loss 1.1103\n",
            "[130/150][100/157]\tTrain Reconstruction Loss 0.0349\t Train Correlation Loss 1.1056\n",
            "[130/150][150/157]\tTrain Reconstruction Loss 0.0338\t Train Correlation Loss 1.0933\n",
            "Val Reconstruction Loss 0.0351\t Val Correlation Loss 1.1009\n",
            "Starting epoch 131\n",
            "[131/150][0/157]\tTrain Reconstruction Loss 0.0348\t Train Correlation Loss 1.0926\n",
            "[131/150][50/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0959\n",
            "[131/150][100/157]\tTrain Reconstruction Loss 0.0341\t Train Correlation Loss 1.0965\n",
            "[131/150][150/157]\tTrain Reconstruction Loss 0.0338\t Train Correlation Loss 1.1021\n",
            "Val Reconstruction Loss 0.0348\t Val Correlation Loss 1.0977\n",
            "Starting epoch 132\n",
            "[132/150][0/157]\tTrain Reconstruction Loss 0.0356\t Train Correlation Loss 1.0924\n",
            "[132/150][50/157]\tTrain Reconstruction Loss 0.0361\t Train Correlation Loss 1.0839\n",
            "[132/150][100/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.1121\n",
            "[132/150][150/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.1103\n",
            "Val Reconstruction Loss 0.0349\t Val Correlation Loss 1.0981\n",
            "Starting epoch 133\n",
            "[133/150][0/157]\tTrain Reconstruction Loss 0.0338\t Train Correlation Loss 1.0977\n",
            "[133/150][50/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0970\n",
            "[133/150][100/157]\tTrain Reconstruction Loss 0.0357\t Train Correlation Loss 1.0936\n",
            "[133/150][150/157]\tTrain Reconstruction Loss 0.0353\t Train Correlation Loss 1.0851\n",
            "Val Reconstruction Loss 0.0351\t Val Correlation Loss 1.0959\n",
            "Starting epoch 134\n",
            "[134/150][0/157]\tTrain Reconstruction Loss 0.0352\t Train Correlation Loss 1.0839\n",
            "[134/150][50/157]\tTrain Reconstruction Loss 0.0339\t Train Correlation Loss 1.0907\n",
            "[134/150][100/157]\tTrain Reconstruction Loss 0.0352\t Train Correlation Loss 1.0886\n",
            "[134/150][150/157]\tTrain Reconstruction Loss 0.0357\t Train Correlation Loss 1.0783\n",
            "Val Reconstruction Loss 0.0352\t Val Correlation Loss 1.0946\n",
            "Starting epoch 135\n",
            "[135/150][0/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.0919\n",
            "[135/150][50/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.1051\n",
            "[135/150][100/157]\tTrain Reconstruction Loss 0.0347\t Train Correlation Loss 1.1014\n",
            "[135/150][150/157]\tTrain Reconstruction Loss 0.0346\t Train Correlation Loss 1.0904\n",
            "Val Reconstruction Loss 0.0353\t Val Correlation Loss 1.0952\n",
            "Starting epoch 136\n",
            "[136/150][0/157]\tTrain Reconstruction Loss 0.0356\t Train Correlation Loss 1.0951\n",
            "[136/150][50/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0966\n",
            "[136/150][100/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.0981\n",
            "[136/150][150/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.1043\n",
            "Val Reconstruction Loss 0.0354\t Val Correlation Loss 1.0960\n",
            "Starting epoch 137\n",
            "[137/150][0/157]\tTrain Reconstruction Loss 0.0361\t Train Correlation Loss 1.0850\n",
            "[137/150][50/157]\tTrain Reconstruction Loss 0.0361\t Train Correlation Loss 1.0994\n",
            "[137/150][100/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.0854\n",
            "[137/150][150/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.1019\n",
            "Val Reconstruction Loss 0.0349\t Val Correlation Loss 1.0940\n",
            "Starting epoch 138\n",
            "[138/150][0/157]\tTrain Reconstruction Loss 0.0349\t Train Correlation Loss 1.0912\n",
            "[138/150][50/157]\tTrain Reconstruction Loss 0.0348\t Train Correlation Loss 1.0894\n",
            "[138/150][100/157]\tTrain Reconstruction Loss 0.0349\t Train Correlation Loss 1.0874\n",
            "[138/150][150/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0832\n",
            "Val Reconstruction Loss 0.0350\t Val Correlation Loss 1.0932\n",
            "Starting epoch 139\n",
            "[139/150][0/157]\tTrain Reconstruction Loss 0.0353\t Train Correlation Loss 1.0850\n",
            "[139/150][50/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.0809\n",
            "[139/150][100/157]\tTrain Reconstruction Loss 0.0343\t Train Correlation Loss 1.0905\n",
            "[139/150][150/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.1092\n",
            "Val Reconstruction Loss 0.0349\t Val Correlation Loss 1.0924\n",
            "Starting epoch 140\n",
            "[140/150][0/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.0975\n",
            "[140/150][50/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0911\n",
            "[140/150][100/157]\tTrain Reconstruction Loss 0.0339\t Train Correlation Loss 1.0876\n",
            "[140/150][150/157]\tTrain Reconstruction Loss 0.0353\t Train Correlation Loss 1.0938\n",
            "Val Reconstruction Loss 0.0352\t Val Correlation Loss 1.0912\n",
            "Starting epoch 141\n",
            "[141/150][0/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.1024\n",
            "[141/150][50/157]\tTrain Reconstruction Loss 0.0340\t Train Correlation Loss 1.0849\n",
            "[141/150][100/157]\tTrain Reconstruction Loss 0.0348\t Train Correlation Loss 1.0987\n",
            "[141/150][150/157]\tTrain Reconstruction Loss 0.0359\t Train Correlation Loss 1.0841\n",
            "Val Reconstruction Loss 0.0353\t Val Correlation Loss 1.0911\n",
            "Starting epoch 142\n",
            "[142/150][0/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.1028\n",
            "[142/150][50/157]\tTrain Reconstruction Loss 0.0357\t Train Correlation Loss 1.0865\n",
            "[142/150][100/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0826\n",
            "[142/150][150/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0818\n",
            "Val Reconstruction Loss 0.0353\t Val Correlation Loss 1.0914\n",
            "Starting epoch 143\n",
            "[143/150][0/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.0933\n",
            "[143/150][50/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.0899\n",
            "[143/150][100/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.0882\n",
            "[143/150][150/157]\tTrain Reconstruction Loss 0.0343\t Train Correlation Loss 1.0932\n",
            "Val Reconstruction Loss 0.0351\t Val Correlation Loss 1.0899\n",
            "Starting epoch 144\n",
            "[144/150][0/157]\tTrain Reconstruction Loss 0.0361\t Train Correlation Loss 1.0930\n",
            "[144/150][50/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.0908\n",
            "[144/150][100/157]\tTrain Reconstruction Loss 0.0357\t Train Correlation Loss 1.0892\n",
            "[144/150][150/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.0829\n",
            "Val Reconstruction Loss 0.0352\t Val Correlation Loss 1.0981\n",
            "Starting epoch 145\n",
            "[145/150][0/157]\tTrain Reconstruction Loss 0.0338\t Train Correlation Loss 1.1095\n",
            "[145/150][50/157]\tTrain Reconstruction Loss 0.0336\t Train Correlation Loss 1.0844\n",
            "[145/150][100/157]\tTrain Reconstruction Loss 0.0359\t Train Correlation Loss 1.0774\n",
            "[145/150][150/157]\tTrain Reconstruction Loss 0.0350\t Train Correlation Loss 1.0906\n",
            "Val Reconstruction Loss 0.0354\t Val Correlation Loss 1.0880\n",
            "Starting epoch 146\n",
            "[146/150][0/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0712\n",
            "[146/150][50/157]\tTrain Reconstruction Loss 0.0350\t Train Correlation Loss 1.0899\n",
            "[146/150][100/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0816\n",
            "[146/150][150/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0745\n",
            "Val Reconstruction Loss 0.0353\t Val Correlation Loss 1.0876\n",
            "Starting epoch 147\n",
            "[147/150][0/157]\tTrain Reconstruction Loss 0.0342\t Train Correlation Loss 1.0848\n",
            "[147/150][50/157]\tTrain Reconstruction Loss 0.0343\t Train Correlation Loss 1.0913\n",
            "[147/150][100/157]\tTrain Reconstruction Loss 0.0346\t Train Correlation Loss 1.0914\n",
            "[147/150][150/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0780\n",
            "Val Reconstruction Loss 0.0353\t Val Correlation Loss 1.0868\n",
            "Starting epoch 148\n",
            "[148/150][0/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.0877\n",
            "[148/150][50/157]\tTrain Reconstruction Loss 0.0337\t Train Correlation Loss 1.0893\n",
            "[148/150][100/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0826\n",
            "[148/150][150/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0915\n",
            "Val Reconstruction Loss 0.0351\t Val Correlation Loss 1.0867\n",
            "Starting epoch 149\n",
            "[149/150][0/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0800\n",
            "[149/150][50/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0785\n",
            "[149/150][100/157]\tTrain Reconstruction Loss 0.0346\t Train Correlation Loss 1.0877\n",
            "[149/150][150/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0855\n",
            "Val Reconstruction Loss 0.0354\t Val Correlation Loss 1.0930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLSK6Jb2u4H1"
      },
      "source": [
        "create_checkpoint()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LF5DNzZxpCq",
        "outputId": "d69da02e-8777-43d3-c271-c0d6305ef755"
      },
      "source": [
        "train_autoenc(150,200)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[150/200][0/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0771\n",
            "[150/200][50/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0813\n",
            "[150/200][100/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0911\n",
            "[150/200][150/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0828\n",
            "Val Reconstruction Loss 0.0355\t Val Correlation Loss 1.0842\n",
            "Starting epoch 151\n",
            "[151/200][0/157]\tTrain Reconstruction Loss 0.0358\t Train Correlation Loss 1.0750\n",
            "[151/200][50/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0875\n",
            "[151/200][100/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0781\n",
            "[151/200][150/157]\tTrain Reconstruction Loss 0.0340\t Train Correlation Loss 1.0939\n",
            "Val Reconstruction Loss 0.0356\t Val Correlation Loss 1.0871\n",
            "Starting epoch 152\n",
            "[152/200][0/157]\tTrain Reconstruction Loss 0.0348\t Train Correlation Loss 1.0954\n",
            "[152/200][50/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0728\n",
            "[152/200][100/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0787\n",
            "[152/200][150/157]\tTrain Reconstruction Loss 0.0352\t Train Correlation Loss 1.0727\n",
            "Val Reconstruction Loss 0.0358\t Val Correlation Loss 1.0845\n",
            "Starting epoch 153\n",
            "[153/200][0/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0794\n",
            "[153/200][50/157]\tTrain Reconstruction Loss 0.0343\t Train Correlation Loss 1.0833\n",
            "[153/200][100/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0862\n",
            "[153/200][150/157]\tTrain Reconstruction Loss 0.0341\t Train Correlation Loss 1.0815\n",
            "Val Reconstruction Loss 0.0354\t Val Correlation Loss 1.0882\n",
            "Starting epoch 154\n",
            "[154/200][0/157]\tTrain Reconstruction Loss 0.0337\t Train Correlation Loss 1.0830\n",
            "[154/200][50/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0886\n",
            "[154/200][100/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0751\n",
            "[154/200][150/157]\tTrain Reconstruction Loss 0.0352\t Train Correlation Loss 1.0750\n",
            "Val Reconstruction Loss 0.0355\t Val Correlation Loss 1.0823\n",
            "Starting epoch 155\n",
            "[155/200][0/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.0751\n",
            "[155/200][50/157]\tTrain Reconstruction Loss 0.0356\t Train Correlation Loss 1.0787\n",
            "[155/200][100/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0880\n",
            "[155/200][150/157]\tTrain Reconstruction Loss 0.0348\t Train Correlation Loss 1.0873\n",
            "Val Reconstruction Loss 0.0358\t Val Correlation Loss 1.0827\n",
            "Starting epoch 156\n",
            "[156/200][0/157]\tTrain Reconstruction Loss 0.0357\t Train Correlation Loss 1.0754\n",
            "[156/200][50/157]\tTrain Reconstruction Loss 0.0353\t Train Correlation Loss 1.0722\n",
            "[156/200][100/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0756\n",
            "[156/200][150/157]\tTrain Reconstruction Loss 0.0353\t Train Correlation Loss 1.0835\n",
            "Val Reconstruction Loss 0.0361\t Val Correlation Loss 1.0856\n",
            "Starting epoch 157\n",
            "[157/200][0/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0766\n",
            "[157/200][50/157]\tTrain Reconstruction Loss 0.0360\t Train Correlation Loss 1.0725\n",
            "[157/200][100/157]\tTrain Reconstruction Loss 0.0349\t Train Correlation Loss 1.0748\n",
            "[157/200][150/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.0864\n",
            "Val Reconstruction Loss 0.0355\t Val Correlation Loss 1.0803\n",
            "Starting epoch 158\n",
            "[158/200][0/157]\tTrain Reconstruction Loss 0.0359\t Train Correlation Loss 1.0732\n",
            "[158/200][50/157]\tTrain Reconstruction Loss 0.0347\t Train Correlation Loss 1.0933\n",
            "[158/200][100/157]\tTrain Reconstruction Loss 0.0356\t Train Correlation Loss 1.0789\n",
            "[158/200][150/157]\tTrain Reconstruction Loss 0.0359\t Train Correlation Loss 1.0829\n",
            "Val Reconstruction Loss 0.0355\t Val Correlation Loss 1.0813\n",
            "Starting epoch 159\n",
            "[159/200][0/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.0860\n",
            "[159/200][50/157]\tTrain Reconstruction Loss 0.0356\t Train Correlation Loss 1.0830\n",
            "[159/200][100/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0717\n",
            "[159/200][150/157]\tTrain Reconstruction Loss 0.0349\t Train Correlation Loss 1.0857\n",
            "Val Reconstruction Loss 0.0356\t Val Correlation Loss 1.0810\n",
            "Starting epoch 160\n",
            "[160/200][0/157]\tTrain Reconstruction Loss 0.0341\t Train Correlation Loss 1.0931\n",
            "[160/200][50/157]\tTrain Reconstruction Loss 0.0335\t Train Correlation Loss 1.0791\n",
            "[160/200][100/157]\tTrain Reconstruction Loss 0.0339\t Train Correlation Loss 1.0949\n",
            "[160/200][150/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.0754\n",
            "Val Reconstruction Loss 0.0356\t Val Correlation Loss 1.0866\n",
            "Starting epoch 161\n",
            "[161/200][0/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0796\n",
            "[161/200][50/157]\tTrain Reconstruction Loss 0.0353\t Train Correlation Loss 1.0945\n",
            "[161/200][100/157]\tTrain Reconstruction Loss 0.0347\t Train Correlation Loss 1.0724\n",
            "[161/200][150/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0731\n",
            "Val Reconstruction Loss 0.0363\t Val Correlation Loss 1.0829\n",
            "Starting epoch 162\n",
            "[162/200][0/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0804\n",
            "[162/200][50/157]\tTrain Reconstruction Loss 0.0359\t Train Correlation Loss 1.0764\n",
            "[162/200][100/157]\tTrain Reconstruction Loss 0.0358\t Train Correlation Loss 1.0755\n",
            "[162/200][150/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0782\n",
            "Val Reconstruction Loss 0.0362\t Val Correlation Loss 1.0823\n",
            "Starting epoch 163\n",
            "[163/200][0/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0596\n",
            "[163/200][50/157]\tTrain Reconstruction Loss 0.0350\t Train Correlation Loss 1.0797\n",
            "[163/200][100/157]\tTrain Reconstruction Loss 0.0359\t Train Correlation Loss 1.0842\n",
            "[163/200][150/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.0838\n",
            "Val Reconstruction Loss 0.0358\t Val Correlation Loss 1.0776\n",
            "Starting epoch 164\n",
            "[164/200][0/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0776\n",
            "[164/200][50/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0743\n",
            "[164/200][100/157]\tTrain Reconstruction Loss 0.0359\t Train Correlation Loss 1.0750\n",
            "[164/200][150/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0701\n",
            "Val Reconstruction Loss 0.0357\t Val Correlation Loss 1.0768\n",
            "Starting epoch 165\n",
            "[165/200][0/157]\tTrain Reconstruction Loss 0.0357\t Train Correlation Loss 1.0746\n",
            "[165/200][50/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.0771\n",
            "[165/200][100/157]\tTrain Reconstruction Loss 0.0336\t Train Correlation Loss 1.0842\n",
            "[165/200][150/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0681\n",
            "Val Reconstruction Loss 0.0360\t Val Correlation Loss 1.0748\n",
            "Starting epoch 166\n",
            "[166/200][0/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0575\n",
            "[166/200][50/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0896\n",
            "[166/200][100/157]\tTrain Reconstruction Loss 0.0343\t Train Correlation Loss 1.0800\n",
            "[166/200][150/157]\tTrain Reconstruction Loss 0.0357\t Train Correlation Loss 1.0841\n",
            "Val Reconstruction Loss 0.0359\t Val Correlation Loss 1.0804\n",
            "Starting epoch 167\n",
            "[167/200][0/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0838\n",
            "[167/200][50/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0656\n",
            "[167/200][100/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0676\n",
            "[167/200][150/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0650\n",
            "Val Reconstruction Loss 0.0357\t Val Correlation Loss 1.0786\n",
            "Starting epoch 168\n",
            "[168/200][0/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0827\n",
            "[168/200][50/157]\tTrain Reconstruction Loss 0.0350\t Train Correlation Loss 1.0744\n",
            "[168/200][100/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.0689\n",
            "[168/200][150/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0727\n",
            "Val Reconstruction Loss 0.0361\t Val Correlation Loss 1.0769\n",
            "Starting epoch 169\n",
            "[169/200][0/157]\tTrain Reconstruction Loss 0.0350\t Train Correlation Loss 1.0842\n",
            "[169/200][50/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0631\n",
            "[169/200][100/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0680\n",
            "[169/200][150/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0704\n",
            "Val Reconstruction Loss 0.0360\t Val Correlation Loss 1.0734\n",
            "Starting epoch 170\n",
            "[170/200][0/157]\tTrain Reconstruction Loss 0.0356\t Train Correlation Loss 1.0761\n",
            "[170/200][50/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0714\n",
            "[170/200][100/157]\tTrain Reconstruction Loss 0.0356\t Train Correlation Loss 1.0689\n",
            "[170/200][150/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.0704\n",
            "Val Reconstruction Loss 0.0358\t Val Correlation Loss 1.0763\n",
            "Starting epoch 171\n",
            "[171/200][0/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0659\n",
            "[171/200][50/157]\tTrain Reconstruction Loss 0.0358\t Train Correlation Loss 1.0759\n",
            "[171/200][100/157]\tTrain Reconstruction Loss 0.0357\t Train Correlation Loss 1.0724\n",
            "[171/200][150/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0695\n",
            "Val Reconstruction Loss 0.0364\t Val Correlation Loss 1.0735\n",
            "Starting epoch 172\n",
            "[172/200][0/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0672\n",
            "[172/200][50/157]\tTrain Reconstruction Loss 0.0348\t Train Correlation Loss 1.0803\n",
            "[172/200][100/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0698\n",
            "[172/200][150/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0635\n",
            "Val Reconstruction Loss 0.0362\t Val Correlation Loss 1.0734\n",
            "Starting epoch 173\n",
            "[173/200][0/157]\tTrain Reconstruction Loss 0.0361\t Train Correlation Loss 1.0884\n",
            "[173/200][50/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0686\n",
            "[173/200][100/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0718\n",
            "[173/200][150/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0687\n",
            "Val Reconstruction Loss 0.0364\t Val Correlation Loss 1.0732\n",
            "Starting epoch 174\n",
            "[174/200][0/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0736\n",
            "[174/200][50/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.0782\n",
            "[174/200][100/157]\tTrain Reconstruction Loss 0.0356\t Train Correlation Loss 1.0775\n",
            "[174/200][150/157]\tTrain Reconstruction Loss 0.0360\t Train Correlation Loss 1.0693\n",
            "Val Reconstruction Loss 0.0361\t Val Correlation Loss 1.0709\n",
            "Starting epoch 175\n",
            "[175/200][0/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0733\n",
            "[175/200][50/157]\tTrain Reconstruction Loss 0.0350\t Train Correlation Loss 1.0804\n",
            "[175/200][100/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0767\n",
            "[175/200][150/157]\tTrain Reconstruction Loss 0.0354\t Train Correlation Loss 1.0625\n",
            "Val Reconstruction Loss 0.0361\t Val Correlation Loss 1.0732\n",
            "Starting epoch 176\n",
            "[176/200][0/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0663\n",
            "[176/200][50/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0693\n",
            "[176/200][100/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0662\n",
            "[176/200][150/157]\tTrain Reconstruction Loss 0.0358\t Train Correlation Loss 1.0703\n",
            "Val Reconstruction Loss 0.0366\t Val Correlation Loss 1.0739\n",
            "Starting epoch 177\n",
            "[177/200][0/157]\tTrain Reconstruction Loss 0.0356\t Train Correlation Loss 1.0746\n",
            "[177/200][50/157]\tTrain Reconstruction Loss 0.0350\t Train Correlation Loss 1.0827\n",
            "[177/200][100/157]\tTrain Reconstruction Loss 0.0344\t Train Correlation Loss 1.0787\n",
            "[177/200][150/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0589\n",
            "Val Reconstruction Loss 0.0363\t Val Correlation Loss 1.0740\n",
            "Starting epoch 178\n",
            "[178/200][0/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0616\n",
            "[178/200][50/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0716\n",
            "[178/200][100/157]\tTrain Reconstruction Loss 0.0359\t Train Correlation Loss 1.0841\n",
            "[178/200][150/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0569\n",
            "Val Reconstruction Loss 0.0366\t Val Correlation Loss 1.0680\n",
            "Starting epoch 179\n",
            "[179/200][0/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0683\n",
            "[179/200][50/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0560\n",
            "[179/200][100/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0597\n",
            "[179/200][150/157]\tTrain Reconstruction Loss 0.0358\t Train Correlation Loss 1.0701\n",
            "Val Reconstruction Loss 0.0365\t Val Correlation Loss 1.0683\n",
            "Starting epoch 180\n",
            "[180/200][0/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0632\n",
            "[180/200][50/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0563\n",
            "[180/200][100/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0499\n",
            "[180/200][150/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0564\n",
            "Val Reconstruction Loss 0.0369\t Val Correlation Loss 1.0747\n",
            "Starting epoch 181\n",
            "[181/200][0/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0651\n",
            "[181/200][50/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0584\n",
            "[181/200][100/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0676\n",
            "[181/200][150/157]\tTrain Reconstruction Loss 0.0395\t Train Correlation Loss 1.0495\n",
            "Val Reconstruction Loss 0.0363\t Val Correlation Loss 1.0677\n",
            "Starting epoch 182\n",
            "[182/200][0/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0715\n",
            "[182/200][50/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0583\n",
            "[182/200][100/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0654\n",
            "[182/200][150/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0700\n",
            "Val Reconstruction Loss 0.0362\t Val Correlation Loss 1.0716\n",
            "Starting epoch 183\n",
            "[183/200][0/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0639\n",
            "[183/200][50/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0639\n",
            "[183/200][100/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0684\n",
            "[183/200][150/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0768\n",
            "Val Reconstruction Loss 0.0360\t Val Correlation Loss 1.0669\n",
            "Starting epoch 184\n",
            "[184/200][0/157]\tTrain Reconstruction Loss 0.0346\t Train Correlation Loss 1.0689\n",
            "[184/200][50/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0753\n",
            "[184/200][100/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0617\n",
            "[184/200][150/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0659\n",
            "Val Reconstruction Loss 0.0367\t Val Correlation Loss 1.0661\n",
            "Starting epoch 185\n",
            "[185/200][0/157]\tTrain Reconstruction Loss 0.0360\t Train Correlation Loss 1.0705\n",
            "[185/200][50/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0639\n",
            "[185/200][100/157]\tTrain Reconstruction Loss 0.0340\t Train Correlation Loss 1.0734\n",
            "[185/200][150/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0590\n",
            "Val Reconstruction Loss 0.0361\t Val Correlation Loss 1.0659\n",
            "Starting epoch 186\n",
            "[186/200][0/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0671\n",
            "[186/200][50/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0582\n",
            "[186/200][100/157]\tTrain Reconstruction Loss 0.0359\t Train Correlation Loss 1.0739\n",
            "[186/200][150/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0600\n",
            "Val Reconstruction Loss 0.0363\t Val Correlation Loss 1.0668\n",
            "Starting epoch 187\n",
            "[187/200][0/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0608\n",
            "[187/200][50/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0616\n",
            "[187/200][100/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0607\n",
            "[187/200][150/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0570\n",
            "Val Reconstruction Loss 0.0367\t Val Correlation Loss 1.0644\n",
            "Starting epoch 188\n",
            "[188/200][0/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0621\n",
            "[188/200][50/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0593\n",
            "[188/200][100/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0629\n",
            "[188/200][150/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0685\n",
            "Val Reconstruction Loss 0.0366\t Val Correlation Loss 1.0642\n",
            "Starting epoch 189\n",
            "[189/200][0/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0574\n",
            "[189/200][50/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0630\n",
            "[189/200][100/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0663\n",
            "[189/200][150/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0546\n",
            "Val Reconstruction Loss 0.0359\t Val Correlation Loss 1.0687\n",
            "Starting epoch 190\n",
            "[190/200][0/157]\tTrain Reconstruction Loss 0.0358\t Train Correlation Loss 1.0712\n",
            "[190/200][50/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0381\n",
            "[190/200][100/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0525\n",
            "[190/200][150/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0539\n",
            "Val Reconstruction Loss 0.0365\t Val Correlation Loss 1.0633\n",
            "Starting epoch 191\n",
            "[191/200][0/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0671\n",
            "[191/200][50/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0563\n",
            "[191/200][100/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0532\n",
            "[191/200][150/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.0690\n",
            "Val Reconstruction Loss 0.0363\t Val Correlation Loss 1.0649\n",
            "Starting epoch 192\n",
            "[192/200][0/157]\tTrain Reconstruction Loss 0.0337\t Train Correlation Loss 1.0898\n",
            "[192/200][50/157]\tTrain Reconstruction Loss 0.0345\t Train Correlation Loss 1.0764\n",
            "[192/200][100/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0542\n",
            "[192/200][150/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0605\n",
            "Val Reconstruction Loss 0.0369\t Val Correlation Loss 1.0629\n",
            "Starting epoch 193\n",
            "[193/200][0/157]\tTrain Reconstruction Loss 0.0360\t Train Correlation Loss 1.0689\n",
            "[193/200][50/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0608\n",
            "[193/200][100/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0558\n",
            "[193/200][150/157]\tTrain Reconstruction Loss 0.0360\t Train Correlation Loss 1.0601\n",
            "Val Reconstruction Loss 0.0367\t Val Correlation Loss 1.0622\n",
            "Starting epoch 194\n",
            "[194/200][0/157]\tTrain Reconstruction Loss 0.0358\t Train Correlation Loss 1.0634\n",
            "[194/200][50/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0629\n",
            "[194/200][100/157]\tTrain Reconstruction Loss 0.0352\t Train Correlation Loss 1.0716\n",
            "[194/200][150/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0628\n",
            "Val Reconstruction Loss 0.0376\t Val Correlation Loss 1.0623\n",
            "Starting epoch 195\n",
            "[195/200][0/157]\tTrain Reconstruction Loss 0.0398\t Train Correlation Loss 1.0592\n",
            "[195/200][50/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0630\n",
            "[195/200][100/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0578\n",
            "[195/200][150/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0619\n",
            "Val Reconstruction Loss 0.0369\t Val Correlation Loss 1.0607\n",
            "Starting epoch 196\n",
            "[196/200][0/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0567\n",
            "[196/200][50/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0678\n",
            "[196/200][100/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0505\n",
            "[196/200][150/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0574\n",
            "Val Reconstruction Loss 0.0364\t Val Correlation Loss 1.0675\n",
            "Starting epoch 197\n",
            "[197/200][0/157]\tTrain Reconstruction Loss 0.0353\t Train Correlation Loss 1.0650\n",
            "[197/200][50/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0530\n",
            "[197/200][100/157]\tTrain Reconstruction Loss 0.0356\t Train Correlation Loss 1.0637\n",
            "[197/200][150/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0670\n",
            "Val Reconstruction Loss 0.0370\t Val Correlation Loss 1.0595\n",
            "Starting epoch 198\n",
            "[198/200][0/157]\tTrain Reconstruction Loss 0.0355\t Train Correlation Loss 1.0580\n",
            "[198/200][50/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0651\n",
            "[198/200][100/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0596\n",
            "[198/200][150/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0471\n",
            "Val Reconstruction Loss 0.0369\t Val Correlation Loss 1.0595\n",
            "Starting epoch 199\n",
            "[199/200][0/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0570\n",
            "[199/200][50/157]\tTrain Reconstruction Loss 0.0351\t Train Correlation Loss 1.0666\n",
            "[199/200][100/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0650\n",
            "[199/200][150/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0636\n",
            "Val Reconstruction Loss 0.0373\t Val Correlation Loss 1.0604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-bX-UH1yiYH"
      },
      "source": [
        "create_checkpoint()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suay2M2cy-G4",
        "outputId": "95a9effb-ea1f-4db5-c7e5-8880e75818ae"
      },
      "source": [
        "train_autoenc(200,250)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[200/250][0/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0498\n",
            "[200/250][50/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0639\n",
            "[200/250][100/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0567\n",
            "[200/250][150/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0540\n",
            "Val Reconstruction Loss 0.0372\t Val Correlation Loss 1.0588\n",
            "Starting epoch 201\n",
            "[201/250][0/157]\tTrain Reconstruction Loss 0.0360\t Train Correlation Loss 1.0547\n",
            "[201/250][50/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0458\n",
            "[201/250][100/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0544\n",
            "[201/250][150/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0622\n",
            "Val Reconstruction Loss 0.0371\t Val Correlation Loss 1.0579\n",
            "Starting epoch 202\n",
            "[202/250][0/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0534\n",
            "[202/250][50/157]\tTrain Reconstruction Loss 0.0357\t Train Correlation Loss 1.0602\n",
            "[202/250][100/157]\tTrain Reconstruction Loss 0.0353\t Train Correlation Loss 1.0499\n",
            "[202/250][150/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0533\n",
            "Val Reconstruction Loss 0.0373\t Val Correlation Loss 1.0600\n",
            "Starting epoch 203\n",
            "[203/250][0/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0640\n",
            "[203/250][50/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0424\n",
            "[203/250][100/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0626\n",
            "[203/250][150/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0638\n",
            "Val Reconstruction Loss 0.0374\t Val Correlation Loss 1.0574\n",
            "Starting epoch 204\n",
            "[204/250][0/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0437\n",
            "[204/250][50/157]\tTrain Reconstruction Loss 0.0392\t Train Correlation Loss 1.0480\n",
            "[204/250][100/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0462\n",
            "[204/250][150/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0680\n",
            "Val Reconstruction Loss 0.0371\t Val Correlation Loss 1.0579\n",
            "Starting epoch 205\n",
            "[205/250][0/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0509\n",
            "[205/250][50/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0553\n",
            "[205/250][100/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0513\n",
            "[205/250][150/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0455\n",
            "Val Reconstruction Loss 0.0372\t Val Correlation Loss 1.0574\n",
            "Starting epoch 206\n",
            "[206/250][0/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0489\n",
            "[206/250][50/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0523\n",
            "[206/250][100/157]\tTrain Reconstruction Loss 0.0402\t Train Correlation Loss 1.0448\n",
            "[206/250][150/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0631\n",
            "Val Reconstruction Loss 0.0369\t Val Correlation Loss 1.0571\n",
            "Starting epoch 207\n",
            "[207/250][0/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0556\n",
            "[207/250][50/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0489\n",
            "[207/250][100/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0540\n",
            "[207/250][150/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0606\n",
            "Val Reconstruction Loss 0.0377\t Val Correlation Loss 1.0556\n",
            "Starting epoch 208\n",
            "[208/250][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0472\n",
            "[208/250][50/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0636\n",
            "[208/250][100/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0657\n",
            "[208/250][150/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0596\n",
            "Val Reconstruction Loss 0.0375\t Val Correlation Loss 1.0556\n",
            "Starting epoch 209\n",
            "[209/250][0/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0478\n",
            "[209/250][50/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0539\n",
            "[209/250][100/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0443\n",
            "[209/250][150/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0604\n",
            "Val Reconstruction Loss 0.0384\t Val Correlation Loss 1.0575\n",
            "Starting epoch 210\n",
            "[210/250][0/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0538\n",
            "[210/250][50/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0561\n",
            "[210/250][100/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0568\n",
            "[210/250][150/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0556\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0560\n",
            "Starting epoch 211\n",
            "[211/250][0/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0515\n",
            "[211/250][50/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0486\n",
            "[211/250][100/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0648\n",
            "[211/250][150/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0506\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0535\n",
            "Starting epoch 212\n",
            "[212/250][0/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0364\n",
            "[212/250][50/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0468\n",
            "[212/250][100/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0606\n",
            "[212/250][150/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0663\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0528\n",
            "Starting epoch 213\n",
            "[213/250][0/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0344\n",
            "[213/250][50/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0498\n",
            "[213/250][100/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0518\n",
            "[213/250][150/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0610\n",
            "Val Reconstruction Loss 0.0373\t Val Correlation Loss 1.0536\n",
            "Starting epoch 214\n",
            "[214/250][0/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0591\n",
            "[214/250][50/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0594\n",
            "[214/250][100/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0438\n",
            "[214/250][150/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0584\n",
            "Val Reconstruction Loss 0.0373\t Val Correlation Loss 1.0540\n",
            "Starting epoch 215\n",
            "[215/250][0/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0513\n",
            "[215/250][50/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0666\n",
            "[215/250][100/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0413\n",
            "[215/250][150/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0624\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0526\n",
            "Starting epoch 216\n",
            "[216/250][0/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0543\n",
            "[216/250][50/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0484\n",
            "[216/250][100/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0538\n",
            "[216/250][150/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0486\n",
            "Val Reconstruction Loss 0.0377\t Val Correlation Loss 1.0616\n",
            "Starting epoch 217\n",
            "[217/250][0/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0505\n",
            "[217/250][50/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0583\n",
            "[217/250][100/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0618\n",
            "[217/250][150/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0601\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0519\n",
            "Starting epoch 218\n",
            "[218/250][0/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0571\n",
            "[218/250][50/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0446\n",
            "[218/250][100/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0555\n",
            "[218/250][150/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0691\n",
            "Val Reconstruction Loss 0.0373\t Val Correlation Loss 1.0532\n",
            "Starting epoch 219\n",
            "[219/250][0/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0653\n",
            "[219/250][50/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0409\n",
            "[219/250][100/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0649\n",
            "[219/250][150/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0462\n",
            "Val Reconstruction Loss 0.0379\t Val Correlation Loss 1.0525\n",
            "Starting epoch 220\n",
            "[220/250][0/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0630\n",
            "[220/250][50/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0525\n",
            "[220/250][100/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0497\n",
            "[220/250][150/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0593\n",
            "Val Reconstruction Loss 0.0380\t Val Correlation Loss 1.0510\n",
            "Starting epoch 221\n",
            "[221/250][0/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0561\n",
            "[221/250][50/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0458\n",
            "[221/250][100/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0554\n",
            "[221/250][150/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0448\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0501\n",
            "Starting epoch 222\n",
            "[222/250][0/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0484\n",
            "[222/250][50/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0402\n",
            "[222/250][100/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0491\n",
            "[222/250][150/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0384\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0504\n",
            "Starting epoch 223\n",
            "[223/250][0/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0424\n",
            "[223/250][50/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0514\n",
            "[223/250][100/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0401\n",
            "[223/250][150/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0682\n",
            "Val Reconstruction Loss 0.0377\t Val Correlation Loss 1.0500\n",
            "Starting epoch 224\n",
            "[224/250][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0414\n",
            "[224/250][50/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0595\n",
            "[224/250][100/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0330\n",
            "[224/250][150/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0494\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0500\n",
            "Starting epoch 225\n",
            "[225/250][0/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0477\n",
            "[225/250][50/157]\tTrain Reconstruction Loss 0.0360\t Train Correlation Loss 1.0562\n",
            "[225/250][100/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0467\n",
            "[225/250][150/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0569\n",
            "Val Reconstruction Loss 0.0377\t Val Correlation Loss 1.0517\n",
            "Starting epoch 226\n",
            "[226/250][0/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0459\n",
            "[226/250][50/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0451\n",
            "[226/250][100/157]\tTrain Reconstruction Loss 0.0395\t Train Correlation Loss 1.0422\n",
            "[226/250][150/157]\tTrain Reconstruction Loss 0.0361\t Train Correlation Loss 1.0581\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0475\n",
            "Starting epoch 227\n",
            "[227/250][0/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0498\n",
            "[227/250][50/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0418\n",
            "[227/250][100/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0456\n",
            "[227/250][150/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0552\n",
            "Val Reconstruction Loss 0.0392\t Val Correlation Loss 1.0494\n",
            "Starting epoch 228\n",
            "[228/250][0/157]\tTrain Reconstruction Loss 0.0396\t Train Correlation Loss 1.0451\n",
            "[228/250][50/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0453\n",
            "[228/250][100/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0553\n",
            "[228/250][150/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0619\n",
            "Val Reconstruction Loss 0.0384\t Val Correlation Loss 1.0490\n",
            "Starting epoch 229\n",
            "[229/250][0/157]\tTrain Reconstruction Loss 0.0392\t Train Correlation Loss 1.0484\n",
            "[229/250][50/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0595\n",
            "[229/250][100/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0497\n",
            "[229/250][150/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0380\n",
            "Val Reconstruction Loss 0.0379\t Val Correlation Loss 1.0498\n",
            "Starting epoch 230\n",
            "[230/250][0/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0485\n",
            "[230/250][50/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0424\n",
            "[230/250][100/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0436\n",
            "[230/250][150/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0604\n",
            "Val Reconstruction Loss 0.0373\t Val Correlation Loss 1.0491\n",
            "Starting epoch 231\n",
            "[231/250][0/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0488\n",
            "[231/250][50/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0431\n",
            "[231/250][100/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0510\n",
            "[231/250][150/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0604\n",
            "Val Reconstruction Loss 0.0381\t Val Correlation Loss 1.0502\n",
            "Starting epoch 232\n",
            "[232/250][0/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0431\n",
            "[232/250][50/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0505\n",
            "[232/250][100/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0480\n",
            "[232/250][150/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0330\n",
            "Val Reconstruction Loss 0.0381\t Val Correlation Loss 1.0473\n",
            "Starting epoch 233\n",
            "[233/250][0/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0415\n",
            "[233/250][50/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0535\n",
            "[233/250][100/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0501\n",
            "[233/250][150/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0651\n",
            "Val Reconstruction Loss 0.0388\t Val Correlation Loss 1.0447\n",
            "Starting epoch 234\n",
            "[234/250][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0581\n",
            "[234/250][50/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0455\n",
            "[234/250][100/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0614\n",
            "[234/250][150/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0527\n",
            "Val Reconstruction Loss 0.0381\t Val Correlation Loss 1.0459\n",
            "Starting epoch 235\n",
            "[235/250][0/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0398\n",
            "[235/250][50/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0500\n",
            "[235/250][100/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0422\n",
            "[235/250][150/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0532\n",
            "Val Reconstruction Loss 0.0377\t Val Correlation Loss 1.0486\n",
            "Starting epoch 236\n",
            "[236/250][0/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0459\n",
            "[236/250][50/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0318\n",
            "[236/250][100/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0389\n",
            "[236/250][150/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0415\n",
            "Val Reconstruction Loss 0.0377\t Val Correlation Loss 1.0536\n",
            "Starting epoch 237\n",
            "[237/250][0/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0555\n",
            "[237/250][50/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0540\n",
            "[237/250][100/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0597\n",
            "[237/250][150/157]\tTrain Reconstruction Loss 0.0392\t Train Correlation Loss 1.0360\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0456\n",
            "Starting epoch 238\n",
            "[238/250][0/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0427\n",
            "[238/250][50/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0448\n",
            "[238/250][100/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0249\n",
            "[238/250][150/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0512\n",
            "Val Reconstruction Loss 0.0387\t Val Correlation Loss 1.0436\n",
            "Starting epoch 239\n",
            "[239/250][0/157]\tTrain Reconstruction Loss 0.0395\t Train Correlation Loss 1.0399\n",
            "[239/250][50/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0506\n",
            "[239/250][100/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0487\n",
            "[239/250][150/157]\tTrain Reconstruction Loss 0.0360\t Train Correlation Loss 1.0547\n",
            "Val Reconstruction Loss 0.0377\t Val Correlation Loss 1.0455\n",
            "Starting epoch 240\n",
            "[240/250][0/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0543\n",
            "[240/250][50/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0392\n",
            "[240/250][100/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0398\n",
            "[240/250][150/157]\tTrain Reconstruction Loss 0.0395\t Train Correlation Loss 1.0341\n",
            "Val Reconstruction Loss 0.0383\t Val Correlation Loss 1.0437\n",
            "Starting epoch 241\n",
            "[241/250][0/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0480\n",
            "[241/250][50/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0415\n",
            "[241/250][100/157]\tTrain Reconstruction Loss 0.0401\t Train Correlation Loss 1.0377\n",
            "[241/250][150/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0512\n",
            "Val Reconstruction Loss 0.0385\t Val Correlation Loss 1.0450\n",
            "Starting epoch 242\n",
            "[242/250][0/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0411\n",
            "[242/250][50/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0468\n",
            "[242/250][100/157]\tTrain Reconstruction Loss 0.0396\t Train Correlation Loss 1.0339\n",
            "[242/250][150/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0355\n",
            "Val Reconstruction Loss 0.0387\t Val Correlation Loss 1.0425\n",
            "Starting epoch 243\n",
            "[243/250][0/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0447\n",
            "[243/250][50/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0476\n",
            "[243/250][100/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0466\n",
            "[243/250][150/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0339\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0476\n",
            "Starting epoch 244\n",
            "[244/250][0/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0510\n",
            "[244/250][50/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0450\n",
            "[244/250][100/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0390\n",
            "[244/250][150/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0563\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0470\n",
            "Starting epoch 245\n",
            "[245/250][0/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0415\n",
            "[245/250][50/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0350\n",
            "[245/250][100/157]\tTrain Reconstruction Loss 0.0417\t Train Correlation Loss 1.0402\n",
            "[245/250][150/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0447\n",
            "Val Reconstruction Loss 0.0389\t Val Correlation Loss 1.0418\n",
            "Starting epoch 246\n",
            "[246/250][0/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0399\n",
            "[246/250][50/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0511\n",
            "[246/250][100/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0412\n",
            "[246/250][150/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0257\n",
            "Val Reconstruction Loss 0.0384\t Val Correlation Loss 1.0422\n",
            "Starting epoch 247\n",
            "[247/250][0/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0502\n",
            "[247/250][50/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0436\n",
            "[247/250][100/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0268\n",
            "[247/250][150/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0390\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0470\n",
            "Starting epoch 248\n",
            "[248/250][0/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0507\n",
            "[248/250][50/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0481\n",
            "[248/250][100/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0353\n",
            "[248/250][150/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0429\n",
            "Val Reconstruction Loss 0.0383\t Val Correlation Loss 1.0431\n",
            "Starting epoch 249\n",
            "[249/250][0/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0465\n",
            "[249/250][50/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0370\n",
            "[249/250][100/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0440\n",
            "[249/250][150/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0453\n",
            "Val Reconstruction Loss 0.0384\t Val Correlation Loss 1.0442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAefhBsF26_o"
      },
      "source": [
        "create_checkpoint()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eitFmn3z3VHc",
        "outputId": "9c4e46f7-58c7-4def-94f3-d07177a68ff5"
      },
      "source": [
        "train_autoenc(250,300)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[250/300][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0322\n",
            "[250/300][50/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0370\n",
            "[250/300][100/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0420\n",
            "[250/300][150/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0304\n",
            "Val Reconstruction Loss 0.0384\t Val Correlation Loss 1.0477\n",
            "Starting epoch 251\n",
            "[251/300][0/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0547\n",
            "[251/300][50/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0449\n",
            "[251/300][100/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0379\n",
            "[251/300][150/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0493\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0416\n",
            "Starting epoch 252\n",
            "[252/300][0/157]\tTrain Reconstruction Loss 0.0392\t Train Correlation Loss 1.0348\n",
            "[252/300][50/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0334\n",
            "[252/300][100/157]\tTrain Reconstruction Loss 0.0393\t Train Correlation Loss 1.0343\n",
            "[252/300][150/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0406\n",
            "Val Reconstruction Loss 0.0387\t Val Correlation Loss 1.0421\n",
            "Starting epoch 253\n",
            "[253/300][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0389\n",
            "[253/300][50/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0514\n",
            "[253/300][100/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0481\n",
            "[253/300][150/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0468\n",
            "Val Reconstruction Loss 0.0383\t Val Correlation Loss 1.0421\n",
            "Starting epoch 254\n",
            "[254/300][0/157]\tTrain Reconstruction Loss 0.0397\t Train Correlation Loss 1.0237\n",
            "[254/300][50/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0466\n",
            "[254/300][100/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0408\n",
            "[254/300][150/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0579\n",
            "Val Reconstruction Loss 0.0380\t Val Correlation Loss 1.0414\n",
            "Starting epoch 255\n",
            "[255/300][0/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0399\n",
            "[255/300][50/157]\tTrain Reconstruction Loss 0.0400\t Train Correlation Loss 1.0292\n",
            "[255/300][100/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0195\n",
            "[255/300][150/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0448\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0426\n",
            "Starting epoch 256\n",
            "[256/300][0/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0351\n",
            "[256/300][50/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0448\n",
            "[256/300][100/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0451\n",
            "[256/300][150/157]\tTrain Reconstruction Loss 0.0392\t Train Correlation Loss 1.0415\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0416\n",
            "Starting epoch 257\n",
            "[257/300][0/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0423\n",
            "[257/300][50/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0387\n",
            "[257/300][100/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0391\n",
            "[257/300][150/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0471\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0407\n",
            "Starting epoch 258\n",
            "[258/300][0/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0544\n",
            "[258/300][50/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0421\n",
            "[258/300][100/157]\tTrain Reconstruction Loss 0.0395\t Train Correlation Loss 1.0309\n",
            "[258/300][150/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0386\n",
            "Val Reconstruction Loss 0.0385\t Val Correlation Loss 1.0398\n",
            "Starting epoch 259\n",
            "[259/300][0/157]\tTrain Reconstruction Loss 0.0395\t Train Correlation Loss 1.0386\n",
            "[259/300][50/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0285\n",
            "[259/300][100/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0427\n",
            "[259/300][150/157]\tTrain Reconstruction Loss 0.0397\t Train Correlation Loss 1.0382\n",
            "Val Reconstruction Loss 0.0389\t Val Correlation Loss 1.0386\n",
            "Starting epoch 260\n",
            "[260/300][0/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0383\n",
            "[260/300][50/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0505\n",
            "[260/300][100/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0293\n",
            "[260/300][150/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0383\n",
            "Val Reconstruction Loss 0.0391\t Val Correlation Loss 1.0433\n",
            "Starting epoch 261\n",
            "[261/300][0/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0310\n",
            "[261/300][50/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0327\n",
            "[261/300][100/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0508\n",
            "[261/300][150/157]\tTrain Reconstruction Loss 0.0398\t Train Correlation Loss 1.0279\n",
            "Val Reconstruction Loss 0.0384\t Val Correlation Loss 1.0406\n",
            "Starting epoch 262\n",
            "[262/300][0/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0457\n",
            "[262/300][50/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0344\n",
            "[262/300][100/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0433\n",
            "[262/300][150/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0441\n",
            "Val Reconstruction Loss 0.0388\t Val Correlation Loss 1.0387\n",
            "Starting epoch 263\n",
            "[263/300][0/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0363\n",
            "[263/300][50/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0397\n",
            "[263/300][100/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0348\n",
            "[263/300][150/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0380\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0402\n",
            "Starting epoch 264\n",
            "[264/300][0/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0472\n",
            "[264/300][50/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0347\n",
            "[264/300][100/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0463\n",
            "[264/300][150/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0462\n",
            "Val Reconstruction Loss 0.0384\t Val Correlation Loss 1.0388\n",
            "Starting epoch 265\n",
            "[265/300][0/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0379\n",
            "[265/300][50/157]\tTrain Reconstruction Loss 0.0399\t Train Correlation Loss 1.0191\n",
            "[265/300][100/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0460\n",
            "[265/300][150/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0446\n",
            "Val Reconstruction Loss 0.0380\t Val Correlation Loss 1.0400\n",
            "Starting epoch 266\n",
            "[266/300][0/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0334\n",
            "[266/300][50/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0383\n",
            "[266/300][100/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0326\n",
            "[266/300][150/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0451\n",
            "Val Reconstruction Loss 0.0385\t Val Correlation Loss 1.0379\n",
            "Starting epoch 267\n",
            "[267/300][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0215\n",
            "[267/300][50/157]\tTrain Reconstruction Loss 0.0392\t Train Correlation Loss 1.0306\n",
            "[267/300][100/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0295\n",
            "[267/300][150/157]\tTrain Reconstruction Loss 0.0400\t Train Correlation Loss 1.0222\n",
            "Val Reconstruction Loss 0.0392\t Val Correlation Loss 1.0435\n",
            "Starting epoch 268\n",
            "[268/300][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0500\n",
            "[268/300][50/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0395\n",
            "[268/300][100/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0442\n",
            "[268/300][150/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0385\n",
            "Val Reconstruction Loss 0.0392\t Val Correlation Loss 1.0375\n",
            "Starting epoch 269\n",
            "[269/300][0/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0408\n",
            "[269/300][50/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0403\n",
            "[269/300][100/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0516\n",
            "[269/300][150/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0354\n",
            "Val Reconstruction Loss 0.0387\t Val Correlation Loss 1.0395\n",
            "Starting epoch 270\n",
            "[270/300][0/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0566\n",
            "[270/300][50/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0467\n",
            "[270/300][100/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0338\n",
            "[270/300][150/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0382\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0377\n",
            "Starting epoch 271\n",
            "[271/300][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0296\n",
            "[271/300][50/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0511\n",
            "[271/300][100/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0341\n",
            "[271/300][150/157]\tTrain Reconstruction Loss 0.0397\t Train Correlation Loss 1.0286\n",
            "Val Reconstruction Loss 0.0385\t Val Correlation Loss 1.0366\n",
            "Starting epoch 272\n",
            "[272/300][0/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0433\n",
            "[272/300][50/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0372\n",
            "[272/300][100/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0390\n",
            "[272/300][150/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0377\n",
            "Val Reconstruction Loss 0.0389\t Val Correlation Loss 1.0360\n",
            "Starting epoch 273\n",
            "[273/300][0/157]\tTrain Reconstruction Loss 0.0393\t Train Correlation Loss 1.0182\n",
            "[273/300][50/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0469\n",
            "[273/300][100/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0333\n",
            "[273/300][150/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0307\n",
            "Val Reconstruction Loss 0.0389\t Val Correlation Loss 1.0436\n",
            "Starting epoch 274\n",
            "[274/300][0/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0490\n",
            "[274/300][50/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0403\n",
            "[274/300][100/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0387\n",
            "[274/300][150/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0354\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0350\n",
            "Starting epoch 275\n",
            "[275/300][0/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0390\n",
            "[275/300][50/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0223\n",
            "[275/300][100/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0272\n",
            "[275/300][150/157]\tTrain Reconstruction Loss 0.0397\t Train Correlation Loss 1.0341\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0400\n",
            "Starting epoch 276\n",
            "[276/300][0/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0235\n",
            "[276/300][50/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0548\n",
            "[276/300][100/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0315\n",
            "[276/300][150/157]\tTrain Reconstruction Loss 0.0393\t Train Correlation Loss 1.0311\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0382\n",
            "Starting epoch 277\n",
            "[277/300][0/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0420\n",
            "[277/300][50/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0354\n",
            "[277/300][100/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0420\n",
            "[277/300][150/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0366\n",
            "Val Reconstruction Loss 0.0384\t Val Correlation Loss 1.0362\n",
            "Starting epoch 278\n",
            "[278/300][0/157]\tTrain Reconstruction Loss 0.0407\t Train Correlation Loss 1.0148\n",
            "[278/300][50/157]\tTrain Reconstruction Loss 0.0400\t Train Correlation Loss 1.0308\n",
            "[278/300][100/157]\tTrain Reconstruction Loss 0.0366\t Train Correlation Loss 1.0393\n",
            "[278/300][150/157]\tTrain Reconstruction Loss 0.0393\t Train Correlation Loss 1.0298\n",
            "Val Reconstruction Loss 0.0387\t Val Correlation Loss 1.0378\n",
            "Starting epoch 279\n",
            "[279/300][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0302\n",
            "[279/300][50/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0314\n",
            "[279/300][100/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0302\n",
            "[279/300][150/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0385\n",
            "Val Reconstruction Loss 0.0380\t Val Correlation Loss 1.0355\n",
            "Starting epoch 280\n",
            "[280/300][0/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0411\n",
            "[280/300][50/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0443\n",
            "[280/300][100/157]\tTrain Reconstruction Loss 0.0400\t Train Correlation Loss 1.0412\n",
            "[280/300][150/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0224\n",
            "Val Reconstruction Loss 0.0392\t Val Correlation Loss 1.0335\n",
            "Starting epoch 281\n",
            "[281/300][0/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0436\n",
            "[281/300][50/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0415\n",
            "[281/300][100/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0194\n",
            "[281/300][150/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0250\n",
            "Val Reconstruction Loss 0.0385\t Val Correlation Loss 1.0373\n",
            "Starting epoch 282\n",
            "[282/300][0/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0501\n",
            "[282/300][50/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0337\n",
            "[282/300][100/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0438\n",
            "[282/300][150/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0525\n",
            "Val Reconstruction Loss 0.0391\t Val Correlation Loss 1.0379\n",
            "Starting epoch 283\n",
            "[283/300][0/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0440\n",
            "[283/300][50/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0530\n",
            "[283/300][100/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0326\n",
            "[283/300][150/157]\tTrain Reconstruction Loss 0.0396\t Train Correlation Loss 1.0406\n",
            "Val Reconstruction Loss 0.0381\t Val Correlation Loss 1.0349\n",
            "Starting epoch 284\n",
            "[284/300][0/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0393\n",
            "[284/300][50/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0351\n",
            "[284/300][100/157]\tTrain Reconstruction Loss 0.0393\t Train Correlation Loss 1.0376\n",
            "[284/300][150/157]\tTrain Reconstruction Loss 0.0401\t Train Correlation Loss 1.0311\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0349\n",
            "Starting epoch 285\n",
            "[285/300][0/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0350\n",
            "[285/300][50/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0396\n",
            "[285/300][100/157]\tTrain Reconstruction Loss 0.0392\t Train Correlation Loss 1.0155\n",
            "[285/300][150/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0395\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0343\n",
            "Starting epoch 286\n",
            "[286/300][0/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0289\n",
            "[286/300][50/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0303\n",
            "[286/300][100/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0447\n",
            "[286/300][150/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0186\n",
            "Val Reconstruction Loss 0.0383\t Val Correlation Loss 1.0351\n",
            "Starting epoch 287\n",
            "[287/300][0/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0205\n",
            "[287/300][50/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0268\n",
            "[287/300][100/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0384\n",
            "[287/300][150/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0291\n",
            "Val Reconstruction Loss 0.0380\t Val Correlation Loss 1.0353\n",
            "Starting epoch 288\n",
            "[288/300][0/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0333\n",
            "[288/300][50/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0318\n",
            "[288/300][100/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0381\n",
            "[288/300][150/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0246\n",
            "Val Reconstruction Loss 0.0380\t Val Correlation Loss 1.0332\n",
            "Starting epoch 289\n",
            "[289/300][0/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0432\n",
            "[289/300][50/157]\tTrain Reconstruction Loss 0.0393\t Train Correlation Loss 1.0325\n",
            "[289/300][100/157]\tTrain Reconstruction Loss 0.0402\t Train Correlation Loss 1.0227\n",
            "[289/300][150/157]\tTrain Reconstruction Loss 0.0362\t Train Correlation Loss 1.0404\n",
            "Val Reconstruction Loss 0.0380\t Val Correlation Loss 1.0346\n",
            "Starting epoch 290\n",
            "[290/300][0/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0098\n",
            "[290/300][50/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0382\n",
            "[290/300][100/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0377\n",
            "[290/300][150/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0388\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0320\n",
            "Starting epoch 291\n",
            "[291/300][0/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0297\n",
            "[291/300][50/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0338\n",
            "[291/300][100/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0328\n",
            "[291/300][150/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0313\n",
            "Val Reconstruction Loss 0.0385\t Val Correlation Loss 1.0318\n",
            "Starting epoch 292\n",
            "[292/300][0/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0302\n",
            "[292/300][50/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0328\n",
            "[292/300][100/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0320\n",
            "[292/300][150/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0328\n",
            "Val Reconstruction Loss 0.0380\t Val Correlation Loss 1.0321\n",
            "Starting epoch 293\n",
            "[293/300][0/157]\tTrain Reconstruction Loss 0.0405\t Train Correlation Loss 1.0280\n",
            "[293/300][50/157]\tTrain Reconstruction Loss 0.0373\t Train Correlation Loss 1.0356\n",
            "[293/300][100/157]\tTrain Reconstruction Loss 0.0398\t Train Correlation Loss 1.0364\n",
            "[293/300][150/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0382\n",
            "Val Reconstruction Loss 0.0384\t Val Correlation Loss 1.0326\n",
            "Starting epoch 294\n",
            "[294/300][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0221\n",
            "[294/300][50/157]\tTrain Reconstruction Loss 0.0397\t Train Correlation Loss 1.0329\n",
            "[294/300][100/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0436\n",
            "[294/300][150/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0334\n",
            "Val Reconstruction Loss 0.0385\t Val Correlation Loss 1.0324\n",
            "Starting epoch 295\n",
            "[295/300][0/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0298\n",
            "[295/300][50/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0376\n",
            "[295/300][100/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0384\n",
            "[295/300][150/157]\tTrain Reconstruction Loss 0.0364\t Train Correlation Loss 1.0255\n",
            "Val Reconstruction Loss 0.0389\t Val Correlation Loss 1.0299\n",
            "Starting epoch 296\n",
            "[296/300][0/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0379\n",
            "[296/300][50/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0343\n",
            "[296/300][100/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0356\n",
            "[296/300][150/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0276\n",
            "Val Reconstruction Loss 0.0383\t Val Correlation Loss 1.0311\n",
            "Starting epoch 297\n",
            "[297/300][0/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0399\n",
            "[297/300][50/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0282\n",
            "[297/300][100/157]\tTrain Reconstruction Loss 0.0393\t Train Correlation Loss 1.0287\n",
            "[297/300][150/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0521\n",
            "Val Reconstruction Loss 0.0381\t Val Correlation Loss 1.0343\n",
            "Starting epoch 298\n",
            "[298/300][0/157]\tTrain Reconstruction Loss 0.0368\t Train Correlation Loss 1.0342\n",
            "[298/300][50/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0287\n",
            "[298/300][100/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0342\n",
            "[298/300][150/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0271\n",
            "Val Reconstruction Loss 0.0379\t Val Correlation Loss 1.0353\n",
            "Starting epoch 299\n",
            "[299/300][0/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0285\n",
            "[299/300][50/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0284\n",
            "[299/300][100/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0186\n",
            "[299/300][150/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0470\n",
            "Val Reconstruction Loss 0.0378\t Val Correlation Loss 1.0320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfO7B1bL6Mez"
      },
      "source": [
        "create_checkpoint()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZQ0G0ob6hk2",
        "outputId": "97b5c8e8-c1a2-4f99-f327-968a6cbf77b0"
      },
      "source": [
        "train_autoenc(300,320)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[300/320][0/157]\tTrain Reconstruction Loss 0.0383\t Train Correlation Loss 1.0306\n",
            "[300/320][50/157]\tTrain Reconstruction Loss 0.0410\t Train Correlation Loss 1.0181\n",
            "[300/320][100/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0340\n",
            "[300/320][150/157]\tTrain Reconstruction Loss 0.0403\t Train Correlation Loss 1.0300\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0331\n",
            "Starting epoch 301\n",
            "[301/320][0/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0350\n",
            "[301/320][50/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0327\n",
            "[301/320][100/157]\tTrain Reconstruction Loss 0.0401\t Train Correlation Loss 1.0165\n",
            "[301/320][150/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0244\n",
            "Val Reconstruction Loss 0.0381\t Val Correlation Loss 1.0310\n",
            "Starting epoch 302\n",
            "[302/320][0/157]\tTrain Reconstruction Loss 0.0382\t Train Correlation Loss 1.0344\n",
            "[302/320][50/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0264\n",
            "[302/320][100/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0316\n",
            "[302/320][150/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0352\n",
            "Val Reconstruction Loss 0.0387\t Val Correlation Loss 1.0290\n",
            "Starting epoch 303\n",
            "[303/320][0/157]\tTrain Reconstruction Loss 0.0392\t Train Correlation Loss 1.0268\n",
            "[303/320][50/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0385\n",
            "[303/320][100/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0262\n",
            "[303/320][150/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0303\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0286\n",
            "Starting epoch 304\n",
            "[304/320][0/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0325\n",
            "[304/320][50/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0218\n",
            "[304/320][100/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0301\n",
            "[304/320][150/157]\tTrain Reconstruction Loss 0.0398\t Train Correlation Loss 1.0219\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0312\n",
            "Starting epoch 305\n",
            "[305/320][0/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0253\n",
            "[305/320][50/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0315\n",
            "[305/320][100/157]\tTrain Reconstruction Loss 0.0367\t Train Correlation Loss 1.0389\n",
            "[305/320][150/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0359\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0302\n",
            "Starting epoch 306\n",
            "[306/320][0/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0377\n",
            "[306/320][50/157]\tTrain Reconstruction Loss 0.0395\t Train Correlation Loss 1.0313\n",
            "[306/320][100/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0271\n",
            "[306/320][150/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0497\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0331\n",
            "Starting epoch 307\n",
            "[307/320][0/157]\tTrain Reconstruction Loss 0.0385\t Train Correlation Loss 1.0174\n",
            "[307/320][50/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0236\n",
            "[307/320][100/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0273\n",
            "[307/320][150/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0285\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0323\n",
            "Starting epoch 308\n",
            "[308/320][0/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0431\n",
            "[308/320][50/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0155\n",
            "[308/320][100/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0288\n",
            "[308/320][150/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0282\n",
            "Val Reconstruction Loss 0.0389\t Val Correlation Loss 1.0295\n",
            "Starting epoch 309\n",
            "[309/320][0/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0351\n",
            "[309/320][50/157]\tTrain Reconstruction Loss 0.0389\t Train Correlation Loss 1.0254\n",
            "[309/320][100/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0250\n",
            "[309/320][150/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0381\n",
            "Val Reconstruction Loss 0.0383\t Val Correlation Loss 1.0301\n",
            "Starting epoch 310\n",
            "[310/320][0/157]\tTrain Reconstruction Loss 0.0378\t Train Correlation Loss 1.0389\n",
            "[310/320][50/157]\tTrain Reconstruction Loss 0.0397\t Train Correlation Loss 1.0402\n",
            "[310/320][100/157]\tTrain Reconstruction Loss 0.0371\t Train Correlation Loss 1.0354\n",
            "[310/320][150/157]\tTrain Reconstruction Loss 0.0375\t Train Correlation Loss 1.0377\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0289\n",
            "Starting epoch 311\n",
            "[311/320][0/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0313\n",
            "[311/320][50/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0112\n",
            "[311/320][100/157]\tTrain Reconstruction Loss 0.0370\t Train Correlation Loss 1.0388\n",
            "[311/320][150/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0260\n",
            "Val Reconstruction Loss 0.0381\t Val Correlation Loss 1.0313\n",
            "Starting epoch 312\n",
            "[312/320][0/157]\tTrain Reconstruction Loss 0.0377\t Train Correlation Loss 1.0309\n",
            "[312/320][50/157]\tTrain Reconstruction Loss 0.0394\t Train Correlation Loss 1.0149\n",
            "[312/320][100/157]\tTrain Reconstruction Loss 0.0369\t Train Correlation Loss 1.0299\n",
            "[312/320][150/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0305\n",
            "Val Reconstruction Loss 0.0379\t Val Correlation Loss 1.0287\n",
            "Starting epoch 313\n",
            "[313/320][0/157]\tTrain Reconstruction Loss 0.0381\t Train Correlation Loss 1.0321\n",
            "[313/320][50/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0306\n",
            "[313/320][100/157]\tTrain Reconstruction Loss 0.0387\t Train Correlation Loss 1.0354\n",
            "[313/320][150/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0299\n",
            "Val Reconstruction Loss 0.0385\t Val Correlation Loss 1.0276\n",
            "Starting epoch 314\n",
            "[314/320][0/157]\tTrain Reconstruction Loss 0.0384\t Train Correlation Loss 1.0318\n",
            "[314/320][50/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0227\n",
            "[314/320][100/157]\tTrain Reconstruction Loss 0.0390\t Train Correlation Loss 1.0195\n",
            "[314/320][150/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0200\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0339\n",
            "Starting epoch 315\n",
            "[315/320][0/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0383\n",
            "[315/320][50/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0376\n",
            "[315/320][100/157]\tTrain Reconstruction Loss 0.0376\t Train Correlation Loss 1.0314\n",
            "[315/320][150/157]\tTrain Reconstruction Loss 0.0374\t Train Correlation Loss 1.0267\n",
            "Val Reconstruction Loss 0.0382\t Val Correlation Loss 1.0326\n",
            "Starting epoch 316\n",
            "[316/320][0/157]\tTrain Reconstruction Loss 0.0391\t Train Correlation Loss 1.0318\n",
            "[316/320][50/157]\tTrain Reconstruction Loss 0.0397\t Train Correlation Loss 1.0235\n",
            "[316/320][100/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0253\n",
            "[316/320][150/157]\tTrain Reconstruction Loss 0.0402\t Train Correlation Loss 1.0250\n",
            "Val Reconstruction Loss 0.0385\t Val Correlation Loss 1.0284\n",
            "Starting epoch 317\n",
            "[317/320][0/157]\tTrain Reconstruction Loss 0.0393\t Train Correlation Loss 1.0247\n",
            "[317/320][50/157]\tTrain Reconstruction Loss 0.0388\t Train Correlation Loss 1.0231\n",
            "[317/320][100/157]\tTrain Reconstruction Loss 0.0402\t Train Correlation Loss 1.0182\n",
            "[317/320][150/157]\tTrain Reconstruction Loss 0.0392\t Train Correlation Loss 1.0403\n",
            "Val Reconstruction Loss 0.0386\t Val Correlation Loss 1.0284\n",
            "Starting epoch 318\n",
            "[318/320][0/157]\tTrain Reconstruction Loss 0.0363\t Train Correlation Loss 1.0482\n",
            "[318/320][50/157]\tTrain Reconstruction Loss 0.0400\t Train Correlation Loss 1.0167\n",
            "[318/320][100/157]\tTrain Reconstruction Loss 0.0386\t Train Correlation Loss 1.0245\n",
            "[318/320][150/157]\tTrain Reconstruction Loss 0.0365\t Train Correlation Loss 1.0430\n",
            "Val Reconstruction Loss 0.0387\t Val Correlation Loss 1.0284\n",
            "Starting epoch 319\n",
            "[319/320][0/157]\tTrain Reconstruction Loss 0.0372\t Train Correlation Loss 1.0349\n",
            "[319/320][50/157]\tTrain Reconstruction Loss 0.0380\t Train Correlation Loss 1.0287\n",
            "[319/320][100/157]\tTrain Reconstruction Loss 0.0379\t Train Correlation Loss 1.0305\n",
            "[319/320][150/157]\tTrain Reconstruction Loss 0.0399\t Train Correlation Loss 1.0228\n",
            "Val Reconstruction Loss 0.0380\t Val Correlation Loss 1.0283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApaqV9FN78Rk"
      },
      "source": [
        "create_checkpoint()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "koPoB3rvCEpJ",
        "outputId": "5b8a8a39-0d37-4b65-9ee2-dacdccd71766"
      },
      "source": [
        "fp_labels = ['real', 'GAN_1', 'GAN_2', 'GAN_3']\n",
        "fig, ax = plt.subplots(1,4, figsize = (19,13))\n",
        "for ind, fp_label in enumerate(fp_labels):\n",
        "  fp = np.load('gdrive/My Drive/Diss/Yu/Fingerprints/print_{}.npy'.format(fp_label))\n",
        "  ax[ind].imshow(fp.reshape(28,28))\n",
        "  ax[ind].set_title(fp_label.replace('_', ' '), fontsize=20)\n",
        "plt.savefig('test.png', format='png', bbox_inches='tight')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1368x936 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6RCzOIzrVrQ"
      },
      "source": [
        "! sudo apt-get install texlive-latex-recommended \n",
        "! sudo apt install texlive-latex-extra\n",
        "! sudo apt install dvipng"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}