import numpy as np
import matplotlib.pyplot as plt
import random
import torch
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import accuracy_score
from itertools import product


import model_architectures as ma
import cv2

labels = ['real', 'GAN 1', 'GAN 2', 'GAN 3']
ground_truth = (['real']*1000) + (['GAN 1']*1000) + (['GAN 2']*1000) + (['GAN 3']*1000)

autoEnc = ma.Autoencoder()
autoenc_model_dict = torch.load('/content/gdrive/My Drive/Diss/trained_models/Autoencoder', map_location=torch.device('cpu'))
autoEnc.load_state_dict(autoenc_model_dict['model_state_dict'])


def initialise_generators(adv2_epoch = 0):
  """Returns the generators of the three GANs loaded with their state dicts

  :param adv_epoch : if non-zero, load in generators finetuned for 
                          adv_epoch epochs, else original (default is 0)
  """
  fname_suffix = ""
  if adv2_epoch :
    fname_suffix = "_finetuned_epoch_{}".format(adv2_epoch)
  netG1 = ma.Generator1(0)
  model_dict1 = torch.load('/content/gdrive/My Drive/Diss/trained_models/GAN_1'+fname_suffix, map_location=torch.device('cpu'))
  netG1.load_state_dict(model_dict1['G_state_dict'])

  netG2 = ma.Generator2(0)
  model_dict2 = torch.load('/content/gdrive/My Drive/Diss/trained_models/GAN_2'+fname_suffix, map_location=torch.device('cpu'))
  netG2.load_state_dict(model_dict2['G_state_dict'])
  
  netG3 = ma.Generator3(0)
  model_dict3 = torch.load('/content/gdrive/My Drive/Diss/trained_models/GAN_3'+fname_suffix, map_location=torch.device('cpu'))
  netG3.load_state_dict(model_dict3['G_state_dict'])

  return (netG1, netG2, netG3)
  
def initialise_discriminators():
  """Returns the discriminators of the three GANs loaded with their state dicts"""
  
  netD1 = ma.Discriminator1(0)
  model_dict1 = torch.load('/content/gdrive/My Drive/Diss/trained_models/GAN_1', map_location=torch.device('cpu'))
  netD1.load_state_dict(model_dict1['D_state_dict'])

  netD2 = ma.Discriminator2(0)
  model_dict2 = torch.load('/content/gdrive/My Drive/Diss/trained_models/GAN_2', map_location=torch.device('cpu'))
  netD2.load_state_dict(model_dict2['D_state_dict'])
  
  netD3 = ma.Discriminator3(0)
  model_dict3 = torch.load('/content/gdrive/My Drive/Diss/trained_models/GAN_3', map_location=torch.device('cpu'))
  netD3.load_state_dict(model_dict3['D_state_dict'])

  return (netD1, netD2, netD3)
  

def generate_test_batch(adv2_epoch = 0):
  """Creates and saves to device test batches composed of images generated by 
      original/finetuned GANs

  :param adv_epoch : if non-zero, generate images from GANs finetuned for 
                          adv_epoch epochs, else use original (default is 0)
  """
  manualSeed = 500
  torch.manual_seed(manualSeed)
  random.seed(manualSeed)
  np.random.seed(manualSeed)
  fixed_noise = torch.randn(1000,  ma.nz, 1, 1)
  
  (netG1, netG2, netG3) = initialise_generators(adv2_epoch)


  fake1_test = netG1(fixed_noise).detach().numpy().reshape(1000,28,28)
  fake2_test = netG2(fixed_noise).detach().numpy().reshape(1000,28,28)
  fake3_test = netG3(fixed_noise).detach().numpy().reshape(1000,28,28)
  
  folder_name = '/content/gdrive/My Drive/Diss/Images_Testing/'
  if adv2_epoch:
    folder_name += 'finetuned_epoch_{}/'.format(adv2_epoch)
  np.save(folder_name+'GAN_1_images', fake1_test)
  np.save(folder_name+'GAN_2_images', fake2_test)
  np.save(folder_name+'GAN_3_images', fake3_test)

def load_fingerprints(fp_extraction_method, denoising_method="median blur"):
  """Returns precomputed handcrafted/learned fingerprints

  :param fp_extraction_method : specifies which of handcrafted (Marra) and learned fingerprints
                                (Yu) must be returned
  :param denoising_method : specifies denoising method in case of handcrafted 
                            (default is median blur)
  """
  
  dir = '/content/gdrive/My Drive/Diss/{}/Fingerprints/'.format(fp_extraction_method)
  file_names = ['print_real', 'print_GAN_1', 'print_GAN_2', 'print_GAN_3']
  if(fp_extraction_method == 'Marra'):
    file_names = [f + '_' + denoising_method.replace(" ", "_") for f in file_names]
  fingerprints = [np.load(dir + f + '.npy').flatten() for f in file_names ]
  return fingerprints

def load_test_images(gan_num, adv2_epoch = 0):
  """ Returns precomputed test images from a particular ground-truth source

  :param gan_num : specifies source (0 = real world, 1 = GAN 1, 2 = GAN 2, 3 = GAN 3)
  :param adv_epoch : if non-zero, returned images must be from sources finetuned for 
                          adv_epoch epochs, else use original (default is 0)
  """
  
  file_name = "GAN_{:d}_images.npy".format(gan_num) if gan_num > 0 else "Real_images.npy"
  folder_name = '/content/gdrive/My Drive/Diss/Images_Testing/'
  if adv2_epoch:
    folder_name += 'finetuned_epoch_{}/'.format(adv2_epoch)
  test_imgs = np.load(folder_name+file_name)
  return test_imgs

def extract_fingerprint(img, fp_extraction_method, denoising_method = 'median blur'):
  """ Extracts and returns the fingerprint of the image given as input

  :param img : image whose fingerprint needs to be extracted
  :param fp_extraction_method : specifies which of the handcrafted (Marra) and 
                              learned (Yu) fingerprint to extract
  :param denoising_method : specifies denoising method in case of handcrafted 
                            (default is median blur)
  """
  
  if (fp_extraction_method == 'Marra'):
      if (denoising_method == "median blur"):
        dst = cv2.medianBlur(img, 3)
      elif (denoising_method == "gaussian blur"):
        dst = cv2.GaussianBlur(img, (3,3), 1)
  elif (fp_extraction_method == 'Yu'):
      dst = autoEnc(torch.from_numpy(img.reshape(1,1,28,28)))
      dst = dst.detach().numpy().reshape(28,28)
  residual = img - dst
  return residual
  

def compute_corr_coeff(gan_num, fp_extraction_method, attack_mode=None, denoising_method="median blur"):
  """ Returns correlation coefficients between residuals of test images from a particular source 
      and each of the source fingerprints

  :param gan_num : specifies source (0 = real world, 1 = GAN 1, 2 = GAN 2, 3 = GAN 3)
  :param fp_extraction_method : specifies which of handcrafted (Marra) and 
                              learned (Yu) fingerprints to extract from test images
  :param attack_method : specifies which attack mode we are operating under, if any
                         (default is None)
  :param denoising_method : specifies denoising method in case of handcrafted 
                            (default is median blur)
  """
  
  coefs_list = [[],[],[],[]]
  test_imgs = load_test_imgs(gan_num)
  fp_list = load_fingerprints(fp_extraction_method, denoising_method)
  if(attack_mode == 'adv1'):
    test_imgs = preprocess_adv1(test_imgs, fp_list, gan_num)
  for i in range(1000):
    img = test_imgs[i]
    residual_flat = extract_fingerprint(img, fp_extraction_method, denoising_method).flatten()
    for i in range(len(coefs_list)):
      coefs_list[i].append(np.corrcoef(fp_list[i], residual_flat)[0][1]) 
  return coefs_list
  

def get_avg_l2_norm_test_img():
  """ Computes average l2 norm of the images in the test set """
  
  sum_l2_norms = 0
  for gan_num in range(4):
    test_imgs = load_test_images(gan_num)
    sum_l2_norms += np.sum([np.linalg.norm(img) for img in test_imgs])
  avg_l2_norm = sum_l2_norms/4000
  return avg_l2_norm

avg_l2_norm_imgs = get_avg_l2_norm_test_img()


def preprocess_adv1(test_imgs, fps, gan_num, attack_strength):
  """ Returns test images preprocessed in preparation for targeted attack 1

  param test_imgs : images to perturb
  param fps : list of fingerprints to perturb with
  param gan_num : specifies source of test_imgs
  param attack_strength : specifies attack strength (l2 norm of perturbation)
  """
  
	fps = [fp.reshape(28,28) for fp in fps]
	fps_scaled = [fp*attack_strength/np.linalg.norm(fp) for fp in fps]
	test_imgs_attacked = [np.float32(np.clip(test_img + fps_scaled[(gan_num+1)%4],0,1)) for test_img in test_imgs]
	return test_imgs_attacked


def preprocess_gaussian(test_imgs, attack_strength):
  """ Returns test images preprocessed in preparation for noise injection attack

  param test_imgs : images to perturb
  param attack_strength : specifies attack strength (l2 norm of perturbation)
  """
  img_shape = test_imgs[0].shape
  test_imgs_attacked = []
  for i in range(len(test_imgs)):
    gauss_noise = np.random.normal(0,0.1, img_shape)
    noise_scaled = gauss_noise * attack_strength/np.linalg.norm(gauss_noise)
    test_imgs_attacked.append(np.float32(np.clip(test_imgs[i] + noise_scaled,0,1)))
  return test_imgs_attacked
  
def preprocess_blurring(test_imgs, attack_strength):
  """ Returns test images preprocessed in preparation for blurring attack

  param test_imgs : images to perturb
  param attack_strength : specifies attack strength (std dev of gaussian blur)
  """

  if(attack_strength == 0):
    return test_imgs
  img_shape = test_imgs[0].shape
  test_imgs_attacked = [np.clip(cv2.GaussianBlur(img, (15, 15), attack_strength),0,1) for img in test_imgs]
  return test_imgs_attacked

    
def get_predictions(fp_extraction_method, fps = None, denoising_method="median blur", attack_mode=None, attack_strength = 0):
  """ Returns attribution predictions on the test set under given conditions

  :param fp_extraction_method : specifies which of handcrafted (Marra) and 
                              learned (Yu) to use for attribution
  :param fps : if not Null, use fps as source fingerprints, else load in default source fingerprints
               (default is Null)
  :param denoising_method : specifies denoising method in case of handcrafted 
                            (default is median blur)
  :param attack_mode : specifies which attack mode we are operating under, if any
                         (default is None)
  :param attack_strength : specifies attack strength (defined differently for different attack modes)
  """
  
  labels = ['real', 'GAN 1', 'GAN 2', 'GAN 3']
  preds = []
  fp_list = []
  
  if not fps:
    fp_list = load_fingerprints(fp_extraction_method, denoising_method)
  else:
    fp_list = fps
  for gan_num in range(4):
    test_imgs = load_test_images(gan_num, attack_strength if attack_mode == 'adv2' else  0)
    if(attack_mode == 'adv1'):
    	test_imgs = preprocess_adv1(test_imgs, fp_list, gan_num, attack_strength)
    elif(attack_mode == 'gaussian'):
    	test_imgs = preprocess_gaussian(test_imgs, attack_strength)
    elif(attack_mode == 'blur'):
    	test_imgs = preprocess_blurring(test_imgs, attack_strength)
    	
    for i in range(1000):
      img = test_imgs[i]
      residual_flat = extract_fingerprint(img, fp_extraction_method, denoising_method).flatten()
      if (fp_extraction_method == 'Marra'):
        dist_list = [np.linalg.norm(fp - residual_flat) for fp in fp_list]
        preds.append(labels[dist_list.index(min(dist_list))])
      elif (fp_extraction_method == 'Yu'):
        coef_list = [np.corrcoef(fp, residual_flat)[0][1] for fp in fp_list]
        preds.append(labels[coef_list.index(max(coef_list))])
  return preds