{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwS2lzfGSzJ98gnLdqET3O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VasundharaAgarwal/GANFingerprinting/blob/main/Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfVRERpBxa5S"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J_DA159xbvE",
        "outputId": "7f2eda24-e695-4a57-d3b8-edfb61bbf22b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxbrPeodxdwU"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/')\n",
        "import model_architectures as ma"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjp2Wu3rxgyj"
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        \n",
        "        #encoder \n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n",
        "        self.maxPool = nn.MaxPool2d(2, 2)  \n",
        "       \n",
        "        # decoder \n",
        "        self.convTr1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\n",
        "        self.convTr2 = nn.ConvTranspose2d(16, 1, 2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.maxPool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.maxPool(x)  \n",
        "        x = F.relu(self.convTr1(x))\n",
        "        x = F.sigmoid(self.convTr2(x))\n",
        "                \n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ujqUR0S49Dl",
        "outputId": "dc9dfb3c-ec5f-4035-b7e3-b529a3289756"
      },
      "source": [
        "autoEnc = Autoencoder()\n",
        "print(autoEnc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autoencoder(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (maxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (convTr1): ConvTranspose2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (convTr2): ConvTranspose2d(16, 3, kernel_size=(2, 2), stride=(2, 2))\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-boLYNncBk4y",
        "outputId": "b126fc41-01d1-4dc5-92f3-7caa31c06aae"
      },
      "source": [
        "x = torch.randn(5,2)\n",
        "x[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.7754, -0.9387])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58_wB0JW-3_q"
      },
      "source": [
        "real_fp = torch.randn(784, requires_grad=True)\n",
        "gan1_fp = torch.randn(784, requires_grad=True)\n",
        "gan2_fp = torch.randn(784, requires_grad=True)\n",
        "gan3_fp = torch.randn(784, requires_grad=True)\n",
        "fps = [real_fp, gan1_fp, gan2_fp, gan3_fp]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcN0Yg8oJxjL",
        "outputId": "4a6656fc-827a-4ee3-c8a1-53a77ac8bb03"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function Tensor.type>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iLTaaix7JJg"
      },
      "source": [
        "def custom_loss(output, target, source):\n",
        "  l1Criterion = nn.L1Loss()\n",
        "  l1_loss = l1Criterion(output, target)\n",
        "  cum_corr_loss = torch.zeros(1)\n",
        "  for i, recon_img in enumerate(output):\n",
        "    target_img = target[i]\n",
        "    img_fp = recon_img - target_img\n",
        "    img_fp_flat = torch.flatten(img_fp)\n",
        "    vimg_fp_flat = img_fp_flat - torch.mean(img_fp_flat)\n",
        "    sum = 0\n",
        "    numerator = 0\n",
        "    for i, fp in enumerate(fps):\n",
        "      vx = vimg_fp_flat\n",
        "      vy = fp - torch.mean(fp)\n",
        "      cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
        "      if(i == source):\n",
        "        numerator = cost\n",
        "      sum+=cost\n",
        "    ind_corr_loss = -torch.log(numerator/sum)\n",
        "    print(\"num = \",numerator)\n",
        "    print(\"sum =\", sum)\n",
        "    print(\"log = \", ind_corr_loss)\n",
        "    cum_corr_loss += ind_corr_loss\n",
        "  return torch.mean(cum_corr_loss) + l1_loss\n",
        "\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s80ro5DCIrnd",
        "outputId": "6b4792d8-685f-4628-ddfa-d1634ef5d93a"
      },
      "source": [
        "img = torch.randn(4,28,28)\n",
        "custom_loss(img, img*2, 0)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num =  tensor(-0.0027, grad_fn=<DivBackward0>)\n",
            "sum = tensor(0.0323, grad_fn=<AddBackward0>)\n",
            "log =  tensor(nan, grad_fn=<NegBackward>)\n",
            "num =  tensor(-0.0149, grad_fn=<DivBackward0>)\n",
            "sum = tensor(0.0772, grad_fn=<AddBackward0>)\n",
            "log =  tensor(nan, grad_fn=<NegBackward>)\n",
            "num =  tensor(0.0114, grad_fn=<DivBackward0>)\n",
            "sum = tensor(-0.0818, grad_fn=<AddBackward0>)\n",
            "log =  tensor(nan, grad_fn=<NegBackward>)\n",
            "num =  tensor(-0.0037, grad_fn=<DivBackward0>)\n",
            "sum = tensor(-0.0118, grad_fn=<AddBackward0>)\n",
            "log =  tensor(1.1560, grad_fn=<NegBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmPGLoQj7oZ_"
      },
      "source": [
        "optimizer = optim.Adam(autoEnc.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spqXyrKf5see"
      },
      "source": [
        "def trainGAN(num, netG, netD):\n",
        "  netG = netG.to(device)\n",
        "  netD = netD.to(device)\n",
        "  optimD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "  optimG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "  img_list = []\n",
        "  D_x_list = []\n",
        "  D_G_z1_list = []\n",
        "  D_G_z2_list = []\n",
        "  iters = 0\n",
        "  for epoch in range(num_epochs):\n",
        "      print(epoch)\n",
        "      # For each batch in the dataloader\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "          ############################\n",
        "          # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "          ###########################\n",
        "          ## Train with all-real batch\n",
        "          netD.zero_grad()\n",
        "          # Format batch\n",
        "          real_cpu = data[0].to(device)\n",
        "          b_size = real_cpu.size(0)\n",
        "          label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "          # Forward pass real batch through D\n",
        "          output = netD(real_cpu).view(-1)\n",
        "          # Calculate loss on all-real batch\n",
        "          errD_real = criterion(output, label)\n",
        "          # Calculate gradients for D in backward pass\n",
        "          errD_real.backward()\n",
        "          D_x = output.mean().item()\n",
        "\n",
        "          ## Train with all-fake batch\n",
        "          # Generate batch of latent vectors\n",
        "          noise = torch.randn(b_size, ma.nz, 1, 1, device=device)\n",
        "          # Generate fake image batch with G\n",
        "          fake = netG(noise)\n",
        "          label.fill_(fake_label)\n",
        "          # Classify all fake batch with D\n",
        "          output = netD(fake.detach()).view(-1)\n",
        "          # Calculate D's loss on the all-fake batch\n",
        "          errD_fake = criterion(output, label)\n",
        "          # Calculate the gradients for this batch\n",
        "          errD_fake.backward()\n",
        "          D_G_z1 = output.mean().item()\n",
        "          # Add the gradients from the all-real and all-fake batches\n",
        "          errD = errD_real + errD_fake\n",
        "          # Update D\n",
        "          optimD.step()\n",
        "\n",
        "          ############################\n",
        "          # (2) Update G network: maximize log(D(G(z)))\n",
        "          ###########################\n",
        "          netG.zero_grad()\n",
        "          label.fill_(real_label)  # fake labels are real for generator cost\n",
        "          # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "          output = netD(fake).view(-1)\n",
        "          # Calculate G's loss based on this output\n",
        "          errG = criterion(output, label)\n",
        "          # Calculate gradients for G\n",
        "          errG.backward()\n",
        "          D_G_z2 = output.mean().item()\n",
        "          # Update G\n",
        "          optimG.step()\n",
        "\n",
        "          # Output training stats\n",
        "          if i % 50 == 0:\n",
        "              print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                    % (epoch, num_epochs, i, len(train_loader),\n",
        "                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "          # Save Losses for plotting later\n",
        "          D_x_list.append(D_x)\n",
        "          D_G_z1_list.append(D_G_z1)\n",
        "          D_G_z2_list.append(D_G_z2)\n",
        "          # Check how the generator is doing by saving G's output on fixed_noise\n",
        "          if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_loader)-1)):\n",
        "              with torch.no_grad():\n",
        "                  fake = netG(fixed_noise).detach().cpu()\n",
        "              img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "          iters += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}